<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>

  


<link href="../calibreHtmlOutBasicCss.css" type="text/css" rel="stylesheet" />

</head>
<body>

<div class="calibreMeta">
  <div class="calibreMetaTitle">
  
  
    
    <h1>
      <a href="../../jhnii3.html">Kafka入门与实践
</a>
    </h1>
    
    
  
  </div>
  <div class="calibreMetaAuthor">
    牟大恩

  </div>
</div>

<div class="calibreMain">

  <div class="calibreEbookContent">
    
      <div class="calibreEbNavTop">
        
          <a href="part0007_split_003.html" class="calibreAPrev">previous page</a>
        

        
          <a href="part0007_split_005.html" class="calibreANext"> next page</a>
        
      </div>
    

    
<h2 id="nav_point_89" class="sigil_not_in_toc">4.4　消费者</h2>

  <p class="zw">当前版本的Kafka还保留Scala版本的两套消费者，本书统称为旧版消费者。旧版消费者属于Kafka核心模块的一部分，分别为SimpleConsumer和ZooKeeperConsumerConnector，我们习惯称SimpleConsumer为低级消费者，称ZooKeeperConsumerConnector为高级消费者。通过Java语言重新实现的消费者KafkaConsumer我们称为新版消费者。</p>

  <h3 id="nav_point_90" class="calibre9">4.4.1　旧版消费者</h3>

  <p class="zw">对于旧版消费者的实现原理并不打算进行过多的讲解，低级消费者直接通过BlockingChannel与相应的代理创建连接，BlockingChannel是Kafka实现的对Java NIO相关通道的封装。而旧版的高级消息者已被废弃，未来的版本将会将其移除，因为高级消费者是基于ZooKeeper管理，存在羊群效应及脑裂问题，已通过Java语言重新设计与实现。在后续章节对消费者API应用也不会涉及高级消费者相关API的介绍。</p>

  <p class="zw">Scala版本所提供的两个级别的消费者主要有以下两点不同。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">通信连接。从通信角度来看，两个级别的区别在于低级消费者直接与指定的代理通过BlockingChannel创建一条Socket连接，而高级消费者依赖通过ZooKeeper与代理进行通信，高级消费者启动时会在ZooKeeper相应路径下进行注册，并通过相应监听器监听节点的变化。消费者平衡（Rebalance）操作也是通过每个消费者在ZooKeeper中注册监听器来触发。依赖ZooKeeper进行消费者平衡的设计方式，在消费者、代理增加或减少抑或是订阅的主题及分区数发生变化触发消费者进行平衡操作时存在羊群效应及脑裂问题。</li>

    <li class="di_1ji_wu_xu_lie_biao">API层。从两个级别的消费者对外提供的API来分析，区别在于高级消费者屏蔽了底层实现细节，调用者无需自己定位查找Leader副本，消费者也无需管理消费的偏移量。低级消费者API实现较复杂但相对灵活，因为调用者可以根据业务需要对主题进行更底层的操作。</li>
  </ul>

  <p class="zw">低级消费者提供了一种灵活控制数据消费的操作，虽然对调用者来说实现起来较复杂，但在某些场景下通过低级消费者反而更加方便。例如，同一条消息多次消费、只读取某个分区信息、消费指定位置的消息等场景。旧版高级消费者由于在设计上存在缺陷因此被重新实现，如果大家应用当前版本的Kafka，强烈推荐使用新版的消费者。关于旧版消费者就简单介绍至此。</p>

  <h3 id="nav_point_91" class="calibre9">4.4.2　KafkaConsumer初始化</h3>

  <p class="zw">KafkaProducer是线程安全的，然而KafkaConsumer是非线程安全的。KafkaConsumer定义了一个acquire()方法用来检测每个方法的调用是否只有一个线程在操作，在KafkaConsumer底层实现时我们可以看到每个方法的第一步就是检测当前方法是否有其他线程正在执行，若有其他线程正在操作即发生并发操作，则抛出ConcurrentModificationException异常。需要注意的是，KafkaConsumer只是通过acquire()方法来检测是否有多线程并发操作，一经发现多线程并发操作就抛出异常，这显然与我们说的同步方法或者锁不同，它并不会因此而阻塞等待，我们可以理解成KafkaConsumer相关的操作是在“轻量级锁”的控制下完成。之所以称为轻量级锁，是因为KafkaConsumer实现了一套思想与锁类似但不等同锁的实现方式，仅通过线程操作记数标记的方式来检测线程是否发生并发操作，以此保证只有一个线程操作。另外，acqurie()方法和release()成对出现与锁的lock和unlock用法类似。</p>

  <p class="zw">KafkaConsumer实现了Consumer接口，Consumer定义了对外提供的API，主要包括订阅消息的subscribe()方法和assign()方法，分别用来指定订阅主题和订阅主题的某些分区；poll()方法，用于拉取消息；seek()方法、seekToBeginning()方法和seekToEnd()方法，用来指定消费起始位置；commitSync()方法和commitAsync()方法，分别用来以同步和异步方式提交消费偏移量；获取消费信息的方法，如获取分区分配关系的assignment()方法、获取下一次消费消息位置的position()方法以及对分区消费控制的pause()方法和resume()方法等。</p>

  <p class="zw">现在，我们简要分析KafkaConsumer初始化的过程。由于KafkaConsumer的实例化过程与KafkaProducer实例化过程比较类似，只不过实例化的组件不同，因此对KafkaConsumer初始化过程不进行详细介绍。我们只简要分析KafkaConsumer初始化过程所定义的变量及其所依赖的组件。</p>

  <p class="zw">KafkaConsumer定义了以下3个Atomic类型的变量用来管理对KafkaConsumer的操作。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">CONSUMER_CLIENT_ID_SEQUENCE：当客户端没有指定消费者的clientId时，Kafka自动为该消费者线程生成一个clientId，该clientId以“consumer-”为前缀，之后为以CONSUMER_CLIENT_ID_SEQUENCE生成的自增整数组合构成的字符串。</li>

    <li class="di_1ji_wu_xu_lie_biao">currentThread：记录当前操作KafkaConsumer的线程Id，该字段起始值为−1（NO_CURR ENT_THREAD）。在acquire()方法中通过检测该字段是否等于−1。若不等于−1则表示已有线程在操作KafkaConsumer，此时抛出ConcurrentModificationException；若该字段值等于−1则表示目前还没有线程在操作，此时调用acquire()方法检测的线程将获得KafkaConsumer的使用权。</li>

    <li class="di_1ji_wu_xu_lie_biao">refcount：用于记录当前操作KafkaConsumer的线程数，初始值为0。在acquire()方法中若检测到当前线程具有对KafkaConsumer的使用权后，refcount值加1操作（incrementAndGet），即记录当前已有一个线程在使用KafkaConsumer。在release()方法中，若refcount减1操作（decrementAndGet）之后的值等于0，则将currentThread的值重置为−1，这样新的线程就可以请求使用KafkaConsumer了。</li>
  </ul>

  <p class="zw">KafkaConsumer实例化就是从ConsumerConfig中提取相应的消费者级别的配置实例化相应的组件。KafkaConsumer较重要的配置如表4-8所示。</p>

  <p class="biao_ti">表4-8　KafkaConsumer重要配置说明</p>

  <table border="1" width="90%" class="calibre11">
    <thead class="calibre12">
      <tr class="calibre13">
        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">属性名</p>
        </th>

        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">默认值</p>
        </th>

        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">描述</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre15">
      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">group.id</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">/</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">消费组id，新版本消费者必须由客户端指定</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">client.id</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">/</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">KafkaConsumer对应的客户端id，客户端可以不指定，Kafka会自动生成一个clientId字符串</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">key.deserializer</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">/</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">消息的Key反序列化类，需要实现org.apache.ka fka.common.seria lization.Deserializer接口</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">value.deserializer</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">/</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">消息的Value反序列化类，需要实现org.apache.ka f ka.common. serialization.Deserializer接口</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">enable.auto.commit</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">true</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">是否开启自动提交消费偏移量</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">max.poll.records</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">500</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">一次拉取消息的最大数量</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">max.poll.interval.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">300000 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">当通过消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时间间隔还没有发起poll操作，则消费组认为该消费者已离开了消费组，将进行平衡操作</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">send.buffer.bytes</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">128 KB</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">Socket发送消息缓冲区大小</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">receive.buffer.bytes</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">64 KB</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">Socket接收消息缓冲区大小</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">fetch.min.bytes</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">1</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">一次拉取操作等待消息的最小字节数</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">fetch.max.bytes</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">50 MB</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">一次拉取操作获取消息的最大字节数</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">session.timeout.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">10000 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">与ZooKeeper会话超时时间，当通过消费组管理消费者时，如果在该配置的时间内组协调器没有收到消费者发来的心跳请求，则协调器会将该消费者从消费组中移除</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">request.timeout.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">305000 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">客户端发送请求后等待回应的超时时间</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">heartbeat.interval.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">3000 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">发送心跳请求的时间间隔</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">auto.commit.interval.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">5000 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">自动提交消费偏移量的时间间隔</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">fetch.max.wait.ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">500 ms</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">若是不满足fetch.min.bytes时，客户端等待请求的最长等待时间</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="zw">KafkaConsumer实例化的主要组件如图4-18所示，各组件作用说明如下。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">ConsumerConfig：消费者级别的配置，将相应配置传递给其他组件。</li>

    <li class="di_1ji_wu_xu_lie_biao">SubscriptionState：维护了消费者订阅和消费消息的情况。该类定义了一系列用于保存订阅信息的字段，主要字段描述如下。

      <ul class="calibre5">
        <li class="di_1ji_wu_xu_lie_biao">subscription：用来保存客户端通过KafkaConsumer.subscribe()方法所订阅的主题列表。</li>

        <li class="di_1ji_wu_xu_lie_biao">subscribedPattern：用来保存通过模式匹配订阅主题的模式。</li>

        <li class="di_1ji_wu_xu_lie_biao">userAssignment：用来保存客户端通过KafkaConsumer.assign()方法所订阅的分区列表。</li>

        <li class="di_1ji_wu_xu_lie_biao">groupSubscription：用来保存该消费者当前订阅的主题列表。</li>

        <li class="di_1ji_wu_xu_lie_biao">assignment：用来保存消费者对所订阅的每个主题分区的消费情况。</li>
      </ul>
    </li>

    <li class="di_1ji_wu_xu_lie_biao">　　SubscriptionState类内部定义了一个私有的枚举类型SubscriptionType，该枚举类定义了消费者订阅消息的四种模式。其中NONE表示初始状态还没有订阅任何主题，AUTO_TOPICS表示按主题名订阅且由指定的分区分配策略自动进行分区与消费者的映射，AUTO_PATTERN表示以正则表达式形式指定消费的主题，分区分配方式与AUTO_TOPICS模式相同，USER_ASSIGNED表示客户端指定了消费者消费的分区。</li>
  </ul>

  <p class="tu"><img alt="" src="../images/00082.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-18　KafkaConsumer依赖的主要组件的类图</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">　　SubscriptionState还定义了一个内部类TopicPartitionState，该类定义了某个消费者对某个TopicPartiton的消费情况，包括下一次拉取消息的起始位置position字段、最近一次已提交消息的位置committed字段、标识TopicPartiton是否被暂停消费的标志位pause字段以及消费偏移量被重置的策略resetStrategy字段。需要注意的是，TopicPartitionState自身并没有主题及分区编号的属性字段，SubscriptionState维护了一个PartitionStates&lt;TopicPartition State&gt;类型的assignment对象，PartitionStates底层是一个LinkedHashMap，Map的Key就是TopicPartitonState所对应的TopicPartition，这样assignment就保存了该消费者所订阅的每个TopicPartition的消费情况。SubscriptionState还维护了一个ConsumerRebalanceListener类型的listener引用，用于消费者发生平衡操作时回调处理，由客户端初始化。</li>

    <li class="di_1ji_wu_xu_lie_biao">ConsumerCoodinator：负责消费者与服务端GroupCoordinator通信，在3.3.1节已进行过详细介绍。</li>

    <li class="di_1ji_wu_xu_lie_biao">ConsumerNetworkClient：对网络层通信NetworkClient的封装，用于消费者与服务端的通信。</li>

    <li class="di_1ji_wu_xu_lie_biao">Fetcher：对ConsumerNetworkClient进行了包装，负责从服务端获取消息。</li>
  </ul>

  <h3 id="nav_point_92" class="calibre9">4.4.3　消费订阅</h3>

  <p class="zw">KafkaConsumer提供了两种订阅消息的方法，一种是通过KafkaConsumer.subscribe()方法指定消息对应的主题，支持以正则表达式方式指定主题，另一种是通过KafkaConsumer.assign()方法指定需要消费的分区。第一种订阅方式由同一个消费组的Leader消费者根据各消费者都支持的分区分配策略为消费者分配分区。同时在订阅主题时可以指定一个ConsumerRebalanc Listener，在消费者发生平衡操作时回调处理。第二种订阅方式客户端直接指定了消费者与分区的对应关系。下面对两种订阅方式分别进行讲解。</p>

  <p class="zw">按主题订阅有3个重载的subscribe()方法，我们首先分析非正则表达式订阅主题的subscri be()方法。不带Consumer RebalanceListener参数的subscribe()方法在底层实现时调用的是带Consumer RebalanceListener参数的subscribe()方法，只不过实例化了一个NoOp Consumer RebalanceListener。</p>

  <p class="zw">subscribe()方法首先通过acquire()方法检测是否有并发操作，若无并发操作，则验证订阅的主题列表topics是否为null，若topics为null则抛出IllegalArgumentException，调用Kafka Consumer.release()方法重置current Thread的值为−1，执行结束；若topics是一个空集合，即集合中无任何元素，则表示客户端取消订阅，因此调用KafkaConsumer.unsu bscribe()执行取消订阅主题操作；否则调用SubscriptionState.subscribe()方法，将订阅的主题列表信息保存到Subscription State.subscription集合和SubscriptionState.groupSubscription集合中，同时将实例化的ConsumerRebalanceListener赋值给SubscriptionState.listener。然后调用Metadata.setTopics()方法更新Metadata维护的该消费组所订阅主题的过期时间。虽然消费者并没有启用主题的过期时间，但仍然需要更新Metadata中主题的过期时间，因为只有这些通过显示设置过期时间的主题才会在Metadata中保留。最后调用KafkaConsumer.release()方法重置currentThread的值为−1，执行结束。该方法执行逻辑如图4-19所示。</p>

  <p class="zw">以正则即模式匹配订阅主题的subscribe()方法提供了一种动态订阅主题的方法，这种方式会定期检查既有主题，当主题或主题的分区发生变化时，自动进行分区重分配。例如，当创建的主题名称符合订阅主题所指定的正则表达式时，该主题就会在定期检查时被加入到该消费组所订阅的主题列表中，删除主题时就会将该主题从消费组订阅主题列表中剔除，主题和分区的变化都会触发该消费组进行重新平衡操作，重新分配各消费者所消费的分区。</p>

  <p class="zw">模式匹配订阅主题方式与直接指定主题列表方式实现逻辑类似，也是首先调用Subscription State.subscribe()方法将订阅关系保存到SubscriptionState维护的用来保存订阅关系的数据结构中，即将订阅主题的模式（Pattern）赋值给subscribedPattern。由于是通过模式匹配来查找订阅的主题，所以接下来需要先设置Metadata.needMetadataForAllTopics标志位为true，然后请求更新Metadata。最后交由消费者协调器ConsumerCoordinator从集群Cluster的当前所有主题中查找满足模式匹配的主题，将主题添加至SubscriptionState的subscription和groupSubscription集合中，并更新这些主题在Metadata中记录的过期时间。</p>

  <p class="tu"><img alt="" src="../images/00083.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-19　KafkaConsumer非模式匹配订阅主题的基本流程</p>

  <p class="zw">客户端指定分区的订阅方式assign()方法实现逻辑与subscribe()类似，也是首先检测是否有并发操作，然后判断请求参数是否合法，即分区是否为null以及是否是空集合，分别进行与subscribe()方法相同处理。然后遍历订阅的分区，构造一个与所订阅分区相对应的主题的topics集合。在将用户指定的消费者分区分配关系保存到SubscriptionState.assignment之前，先调用Consumer.maybeAuto CommitOffsetsNow()方法进行一次消费偏移量提交，以保证同一个消费组下的消费者对分区的消费偏移量已提交，防止重复消费。最后更新所订阅的分区对应的主题过期时间。</p>

  <p class="zw">KafkaConsumer两类订阅方式是互斥的，客户端只能选择其中一种订阅方式，subscribe()方法由Kafka自动进行分区分配，分区自动分配逻辑在3.3节有相应介绍，这里不再赘述。</p>

  <h3 id="nav_point_93" class="calibre9">4.4.4　消费消息</h3>

  <p class="zw">KafkaConsumer提供了一个poll()方法用于从服务端拉取消息，该方法通过Fetcher类来完成消息的拉取及更新消费偏移量，因此对KafkaConsumer消费消息的讲解，首先必须讲解Fetcher拉取消息的过程。</p>

  <h4 class="sigil_not_in_toc1">1．Fetcher拉取消息过程</h4>

  <p class="zw">Fetcher主要功能是负责构造拉取消息的FetchRequest请求，然后通过ConsumerNetwork Client发送FetchRequest请求，最后对返回的结果进行处理并更新缓存中记录的消费位置。在对Fetcher主要功能实现细节进行分析之前，先对Fetcher类定义的主要字段进行介绍。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">Client：ConsumerNetworkClient类型，用于向Kafka相应节点发送网络请求。Consumer NetworkClinet类中定义了一个unsent字段，该字段是Map&lt;Node, List&lt;ClientRequest&gt;&gt;类型，起缓冲队列的作用，保存了每个节点与发送到该节点的ClientRequest请求列表。对于消费消息的ClientRequest对象是由FetchRequest请求转化而来的。</li>

    <li class="di_1ji_wu_xu_lie_biao">metadata：Metadata类型，维护和管理Kafka集群的元数据信息。</li>

    <li class="di_1ji_wu_xu_lie_biao">subscriptions：SubscriptionState类型，通过KafkaConsumer.subscriptions赋值。</li>

    <li class="di_1ji_wu_xu_lie_biao">completedFetches：ConcurrentLinkedQueue&lt;CompletedFetch&gt;类型，其中CompletedFetch类用于保存FetchResponse原始结果，也就是说，此时返回的消息并不是最终返回给客户端的ConsumerRecord而是PartitionData类型。</li>

    <li class="di_1ji_wu_xu_lie_biao">nextInLineRecords：PartitionRecords类型，PartitionRecords是对CompletedFetch解析之后的结果封装类，该类定义了一个List&lt;ConsumerRecord&lt;K, V&gt;&gt;类型的队列，用于保存从CompletedFetch解析后的消息。</li>
  </ul>

  <p class="zw">在对Fetcher类的主要字段进行介绍之后，首先分析用于构造FetchRequest的Fetcher.create FetchRequests()方法的实现逻辑，该方法执行逻辑如下。</p>

  <p class="zw">首先通过medata.fetch()方法获取集群信息Cluster，然后从该消费者所分配的分区subscriptions中查找该消费者 “可拉取消息”（fetchable）的分区集合，一个分区是否为“可拉取消息”，需要满足以下条件。</p>

  <p class="zw">（1）该分区对应的TopicPartitionState中暂停消费标志位pause为false，position不为空。</p>

  <p class="zw">（2）nextInLineRecords中没有来自该分区的消息。</p>

  <p class="zw">（3）completedFetches链表队列中的CompletedFetch不是来自该分区。</p>

  <p class="zw">在查找到所有“可拉取消息”的分区集合之后，迭代集合中的每个分区，查找该分区的Leader副本所在的节点，之所以要查找Leader副本对应的节点，是因为Leader节点负责处理消息的读写请求。如果Leader节点不存在，则设置metadata更新标识为true，触发Kafka元数据信息的更新操作，由于分区Leader副本对应的节点不存在，因此本次拉取消息将忽略该分区。若Leader副本对应的节点存在，同时unsent队列中不包括将要发往该Leader节点的请求，并且inFlightRequests也不包括发往该节点的请求，则构造与该分区对应的FetchRequest.Partition Data对象，并将该对象保存到fetchable集合中，fetchable是一个Map&lt;Node, LinkedHashMap &lt;TopicPartition, FetchRequest.PartitionData&gt;&gt;类型的集合，这样就按分区Leader节点进行了分组，最后再遍历fetchable中的每个元素，根据每个元素的值构造FetchRequest，最终将fetchable转换为Map&lt;Node, FetchRequest&gt;类型的requests集合。</p>

  <p class="zw">通过createFetchRequests()方法处理之后，将对分区的请求按分区Leader副本所在的节点进行了分组，这样就将消费者发往同一个Leader副本节点的所有分区请求封装为一个FetchRequest对象。在完成FetchRequest的构造之后，就可以执行FetchRequest请求的发送了。</p>

  <p class="zw">Fetcher.sendFetches()方法就是负责将createFetchRequest()方法构造的requests集合中的每个FetchRequest发送给相应的节点。该方法会遍历requests集合中的每个元素，调用client.send()方法将FetchRequest构造一个ClientRequest对象，并将其保存到client.unsent缓冲队列中等待发送。同时绑定一个RequestFutureListener，用于对FetchResponse进行处理，RequestFutureListener提供了一个onSuccess()方法和一个onFailure()方法，分别用来在FetchRequest请求处理成功和发生异常时进行相应处理，在onSuccess()方法中主要是对FetchReponse进行处理，用每个分区返回的数据实例化一个CompletedFetch对象，并添加到completedFetches队列中。</p>

  <p class="zw">completedFetches队列中的数据并不是最终返回给客户端的ConsumerRecord类型数据，Fetcher定义了一个fetchedRecords()方法用于将completedFetches队列中保存的消息转为ConsumerRecord类型的消息，同时会更新每个分区对应用的TopicPartitionState的position值，position值是下一次拉取消息的起始位置。</p>

  <p class="zw">至此，Fetcher拉取消息的基本过程分析完毕。现在我们再回到KafkaConsumer.poll()方法处理逻辑的讲解。</p>

  <h4 class="sigil_not_in_toc1">2．KafkaConsumer拉取消息</h4>

  <p class="zw">KafkaConsumer.poll()方法只有一个用于指定在拉取消息时等待时长的参数timeout。timeout字段必须是非负整数，否则抛出IllegalArgumentException异常，若timeout为0，则表示在没有拉取到消息时也无需等待重试再次拉取，而是立即返回给客户端，否则在没有拉取到消息时会在timeout时间内进行重试从服务端拉取消息，直至拉取到消息或者等待时间超过timeout后分别构造响应结果返回给客户端。该方法的核心逻辑是当没有拉取到消息时在timeout时间内循环调用pollOnce(long remaining)方法向服务端发送FetchRequest请求并进行相应处理，若pollOnce()方法拉取到消息，则poll()方法会在将消息返回给客户端之前调用Fetcher.sendFetches()方法发送下一次拉取消息的请求，若没有拉取到消息同时等待时间没有超过timeout设置，则循环调用pollOnce()方法处理，若超时则构造一个空消息集合返回给客户端。</p>

  <p class="zw">pollOnce()方法的主要逻辑是：确保消费组在服务端对应的组协调器已完成分配并正常连接，消费者已加入到该组协调器的管理之中，同时以同步方式调用doAutoCommitOffsetsAsync()方法获取消费初始位置。然后首先调用Fetcher.fetchedRecords()方法，检测是否已获取消息，之所以首先调用Fetcher.fetchedRecords()方法进行处理，是因为KafkaConsumer.poll()方法每次调用pollOnce()方法获取消息之后，紧接着就会发送一次FetchRequest请求以避免阻塞等待。若获取到消息则立即返回到poll()方法执行体，poll()方法会发送下一次拉取消息的FetchRequest请求，然后构造响应结果返回给客户端；否则调用fetcher.sendFetches()方法发送FetchRequest请求，并调用ConsumerNetworkClient.poll()方法执行网络层I/O请求处理，阻塞等待服务端响应之后构造返回结果，在构造返回结果之前，需要检测在长时间的poll()处理之后，消费者是否需要重新加入消费组进行平衡操作，若需要重新加入消费组则返回一个空消息集合，否则调用Fetcher.fetchedRecords()方法获取消息，最后返回poll()方法执行体。</p>

  <p class="zw">KafkaConsumer.poll()方法的执行逻辑流程如图4-20所示。</p>

  <p class="tu"><img alt="" src="../images/00084.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-20　KafkaConsumer.poll()方法的执行逻辑流程</p>

  <p class="zw">这里再着重介绍一下在拉取消息之前如何确定消费起始位置。Kafka提供了由KafkaConsumer自动设置消费起始位置和客户端调用KafkaConsumer相应API两种方式来确定消费起始位置。客户端可以通过KafkaConsumer的seek()方法、seekToBeginning()方法和seekToEnd()方法在消费poll之前指定消费起始位置。其中seek()方法用于指定消费起始位置到一个特定位置；seekTo Beginning()方法指定OffsetResetStrategy为“EARLIEST”，相当于通过配置项auto.offset.reset设置消费偏移量重置策略为earliest的方式；seekToEnd()方法设置OffsetResetStrategy为“LATEST”，相当于通过配置项auto.offset.reset设置消费偏移量重置策略为latest的方式。另一种方式是通过auto.offset.reset配置项设置消费起始位置，默认是采用“LATEST”策略的自动重置消费起始位置，在KafkaConsumer初始化时会读取配置项auto.offset.reset配置的消费位置重置策略初始化SubscriptionState。在pollOnce()方法在执行时会检测是否订阅的主题和分区都已设置了消费起始位置，即订阅列表对应的Topic PartitionState.position不为空，若订阅列表中存在TopicPartitonState.position为空，则先通过Fetcher根据自动重置策略获取消费起始位置，若仍有部分订阅分区没有获取到消费起始位置，则通过Fetcher向Kafka集群发送OffsetFetch Request请求，请求获取消费起始位置。</p>

  <h3 id="nav_point_94" class="calibre9">4.4.5　消费偏移量提交</h3>

  <p class="zw">旧版消费者将消费偏移量提交到ZooKeeper的/consumers/${group.id}/o f fsets/${topic Name}/${partitionId}节点中，然而ZooKeeper并不适合频繁进行读写操作，因此新版消费者进行了改进，将消费偏移量保存到Kafka一个内部主题“__consumer_offsets”中，消费偏移量如同普通消息一样追加到该主题相应的分区当中。Kafka内部主题配置了“compact”策略，这样不仅保证了该主题总保留各分区被消费的最新偏移量，而且控制了该主题的日志容量。通过该消费者对应的消费组（${group.id}）与该主题分区总数取模的方式来确定消费偏移量提交的分区，算法如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">(Math.abs(${group.id}.hashCode() %${offsets.topic.num.partitions}</code></pre>

  <p class="zw">Kafka提供了两种提交消费偏移量的方式：KafkaConsumer自动提交和客户端调用KafkaConsumer相应API提交，后者提交偏移量的方式通常也称为手动提交。</p>

  <p class="zw">由客户端调用API提交消费偏移量需要在实例化KafkaConsumer时设置enable.auto.commit配置项为false。Kafka提供了同步提交commitSync()方法和异步提交commitAsync()方法供客户端提交消费偏移量，这两种方法分别调用的是ConsumerCoordinator的commitOffsetsSync()方法和commitOffsetsAsync()方法。底层实现是通过客户端消费者协调器ConsumerCoordinator发送OffsetCommitRequest请求，服务端组协调器GroupCoordinator进行处理，最终将消费偏移量追加到Kafka内部主题当中。这两种提交消费偏移量方法的区别在于：使用同步提交时，KafkaConsumer在提交请求响应结果返回前会一直被阻塞，在成功提交后才会进行下一次拉取消息操作；异步提交时KafkaConsumer不会被阻塞，这样当提交发生异常时就有可能发生重复消费的问题，但异步方式会提高消费吞吐量。</p>

  <p class="zw">KafkaConsumer自动提交消费偏移量时，在KafkaConsumer实例化时需设置enable.auto.commit为true，同时可以通过配置项auto.commit.interval.ms来设置提交操作的时间间隔。当前版本的KafkaConsumer自动提交消费偏移量并不是通过定时任务周期性地提交，而是在一些特定事件发生时才检测与上一次提交的时间间隔是否超过了${auto.commit.interval.ms}计算出的下一次提交的截止时间nextAutoCommitDeadline，若时间间隔超过了nextAutoCommitDeadline则请求提交偏移量，同时更新下一次提交消费偏移量的nextAuto CommitDeadline。之所以不用定时任务，我认为首先定时任务在后台一直运行是比较耗费资源的，其次这也是没有必要的，因为当消费者启动后并不总能够拉取到消息，这在一定程度上取决于生产者生产消息的速率。需要检测是否提交消费偏移量的事件如下。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">通过KafkaConsumer.assign()订阅分区。这种订阅方式与通过subscribe()订阅方式不同，这种方式直接指定分区，订阅与取消订阅并不会引起消费者进行平衡操作，因此通过这种方式订阅消息时需要进行一次消费偏移量提交检测，以保证该消费者消费偏移量被提交。</li>

    <li class="di_1ji_wu_xu_lie_biao">KafkaConsumer.poll()拉取消息前确保连接到服务端组协调器，即在Consumer Coordinator.poll()方法处理时会进行消费偏移量提交检测。</li>

    <li class="di_1ji_wu_xu_lie_biao">在消费者进行平衡操作前，即在ConsumerCoordinator.onJoinPrepare()方法处理时会进行消费偏移量提交检测。</li>

    <li class="di_1ji_wu_xu_lie_biao">ConsumerCoordinator关闭操作。</li>
  </ul>

  <p class="zw">自动提交消费偏移量底层实现也是调用ConsumerCoordinator的commitOffsetsSync()方法或commitOffsetsAsync()方法进行处理。</p>

  <h3 id="nav_point_95" class="calibre9">4.4.6　心跳探测</h3>

  <p class="zw">KafkaConsumer启动后会定期向服务端组协调器GroupCoordinator发送心跳探测Heartbeat Request请求，通过心跳探测通信双方相互感知对方是否存在并进行相应处理。实现心跳探测功能的核心组件为HeartbeatThread线程，在ConsumerCoordinator实例化时会创建一个守护线程HeartbeatThread，该线程通过计算当前时间与上一次发送心跳时间之差进行相应判断以决定是否要发送心跳探测请求。Kafka封装了一个Heartbeat类，该类定义了一些字段和方法用于HeartbeartThread线程进行心跳探测处理。对消费者心跳探测的分析主要是对该线程的run()方法的执行逻辑进行简要介绍，该方法主要是对以下几种情况进行检测，若满足某个检测条件则进行相应处理，然后结束本次心跳探测处理。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">检测该消费者是否已找到GroupCoordinator，并已加入该组协调器管理之中，若检测到没有对应的GroupCoordinator，则先发送GroupCoordinatorRequest请求查找Group Coordinator。</li>

    <li class="di_1ji_wu_xu_lie_biao">检测与GroupCoordinator之间的会话超时时间sessionTimeout是否已过期，若session Timeout已过期，说明HeartbeatRequest发送后迟迟未收到GroupCoordinator返回的响应，则认为GroupCoordinator不可达已处于“Dead”状态，就会调用coordinatorDead()方法进行处理，清空该GroupCoordinator对应的unsent队列，并将该消费者对应的GroupCoordinator设置为null，这样就会引起重新为该消费者分配一个GroupCoordinator的操作。</li>

    <li class="di_1ji_wu_xu_lie_biao">检查消费者距离上一次poll()操作时间间隔是否已超过最大空闲时间${max.pol l.interva l.ms}，若超过该时间则认为该消费者已离开了该组协调器管理，则调用maybeLeave Group()方法进行处理，发送LeaveGroupRequest请求，并重置generation和memberId值，以准备进行消费者平衡操作。</li>

    <li class="di_1ji_wu_xu_lie_biao">检测是否已达到发送心跳探测时间，若还未到发送心跳探测的时间则继续等待。否则表示要发送心跳探测，则先调用Heartbeat相关方法设置相应字段，为下一次心跳探测进行准备，然后发送HeartbeatRequest请求，并添加一个RequestFutureListener监听器。在监听器中对心跳探测成功与失败分别进行处理，若心跳探测成功则更新Heartbeat.lastHeartbeatReceive字段，若心跳探测失败即发送异常时，则视不同异常进行相应处理，若是RebalanceInProgressException异常则表示正在进行平衡操作，则依然更新Heartbeat.lastHeartbeatReceive字段，否则设置Heartbeat.heartbeatFailed字段为true，以标记心跳探测失败，同时唤醒被wait()处理的心跳探测线程。</li>
  </ul>

  <p class="zw">关于消费者心跳探测就简要介绍至此。对于组协调器如何处理HeartbeatRequest请求，不再进行深入分析，简而言之其处理过程就是组协调器根据消费组所处的状态回调responseCallback返回相应的应答码。需要深入了解的读者，可查阅Kafka源码。</p>

  <h3 id="nav_point_96" class="calibre9">4.4.7　分区数与消费者线程的关系</h3>

  <p class="zw">在介绍消费者线程总数与分区总数关系之前，首先简要介绍Kafka分配线程与分区的分配策略。</p>

  <p class="zw">Kafka提供了配置项partition.assignment.strategy用来设置消费者线程与分区映射关系，Kafka提供了range和round-robin两种分配策略，默认是range分配的策略。</p>

  <h4 class="sigil_not_in_toc1">1．round-robin分配策略</h4>

  <p class="zw">round-robin策略较简单，首先将订阅的主题分区以及消费者线程进行排序，然后通过轮询方式逐个将分区依次分给消费者线程。</p>

  <p class="zw">假设有2个主题，每个主题有3个分区，现在有2个消费者线程订阅了这2个主题，分配结果如图4-21所示。图中，<em class="calibre8">T<sub class="calibre20">n</sub></em>表示主题，<em class="calibre8">P<sub class="calibre20">n</sub></em>表示分区，<em class="calibre8">C<sub class="calibre20">n</sub></em>表示消费者线程。</p>

  <p class="tu"><img alt="" src="../images/00085.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-21　2个主题2个消费者线程的round-robin策略分配结果</p>

  <h4 class="sigil_not_in_toc1">2．range分配策略</h4>

  <p class="zw">range策略即按照线程总数与分区总数进行整除运算计算一个跨度，然后将分区按跨度进行平均分配，以保证分区尽可能均衡地分配给所有消费者线程。该策略具体实现逻辑如下：首先对线程集合按照字典顺序进行排序，然后通过分区总数与消费者线程总数进行整除运算计算每个线程平均分配的分区数numPartitionsPerConsumer，即一个平均跨度，通过分区总数与消费者线程总数取余计算平均之后多余的分区数consumersWithExtraPartition，最后遍历线程集合为每个线程分配分区，从起始分区开始分配，依次为每个线程分配num PartitionsPerConsumer个分区，如果consumers WithExtra Partition不为0，那么在迭代线程集合时，若迭代次数小于consumers WithExtra Partition对应的线程就会分配到num Partitions PerConsumer+1个分区。</p>

  <p class="zw">该策略对应的实现类为RangeAssignor，该分配策略算法如代码清单4-3所示。</p>

  <p class="zw"><strong class="calibre1">代码清单4-3　range分配策略的核心算法</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">......省略其他代码......
// 获取主题分区总数
Integer numPartitionsForTopic = partitionsPerTopic.get(topic); 
if (numPartitionsForTopic == null)
    continue;
// 对线程进行排序
Collections.sort(consumersForTopic); 
// 每个线程至少平均分配的分区数
int numPartitionsPerConsumer = numPartitionsForTopic / consumersForTopic.size();
// 平均分后多余的分区数
int consumersWithExtraPartition = numPartitionsForTopic % consumersForTopic.size();
List&lt;TopicPartition&gt; partitions = AbstractPartitionAssignor.partitions(topic, numPartitionsForTopic);
// 循环为每个线程分配分区
for (int i = 0, n = consumersForTopic.size(); i &lt; n; i++) { 
  // 该线程分配到的分区起始编号
  int start = numPartitionsPerConsumer * i + Math.min(i, 
  consumersWithExtraPartition); 
  // 若平均分配后多余的分区数m，则循环数n小于m的线程应比平均数多分配一个分区
  int length = numPartitionsPerConsumer + (i + 1 &gt; consumersWithExtraPartition ? 0 : 1); 
  assignment.get(consumersForTopic.get(i)).addAll(partitions.subList(start, start 
  + length));
}
......省略其他代码......</code></pre>

  <p class="zw">假设一个主题有10个分区，消费者线程总数为4个。根据range分配策略每个消费者线程分配的分区如图4-22所示。图中，分区以<em class="calibre8">P<sub class="calibre20">n</sub></em>表示，消费者线程以<em class="calibre8">C<sub class="calibre20">n</sub></em>表示，<em class="calibre8">n</em>为从0开始依次递增的整数。</p>

  <p class="zw">如果消费者线程总数大于分区总数，根据range分配策略就可以分析出有部分线程分配不到分区，从而导致该消费者线程接收不到任何消息。例如，一个主题有4个分区，消费者线程总数为5个，根据range分配策略分区与消费者线程的对应关系如图4-23所示。</p>

  <p class="tu"><img alt="" src="../images/00086.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-22　10个分区4个消费者线程的range分配策略</p>

  <p class="tu"><img alt="" src="../images/00087.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-23　4个分区5个消费者线程的range分配策略</p>

  <p class="zw">通过对range分配策略的分析，我们总结以下几条关于分区总数与消费者线程总数对应规则。我们定义<em class="calibre8">P</em><sub class="calibre20">nt</sub>表示分区总数，<em class="calibre8">C</em><sub class="calibre20">nt</sub>表示线程总数。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">若<em class="calibre8">P</em><sub class="calibre20">nt</sub> &gt; <em class="calibre8">C</em><sub class="calibre20">nt</sub>，则有部分消费者线程会分配到多个分区，从而部分消费者线程会收到多个分区消息。这种情况下若对消息顺序有要求的场景，则要实现相应机制来保证消息的顺序。</li>

    <li class="di_1ji_wu_xu_lie_biao">若<em class="calibre8">P</em><sub class="calibre20">nt</sub> = <em class="calibre8">C</em><sub class="calibre20">nt</sub>，则每个消费者线程分配到一个分区，每个消费者收到固定分区的消息。</li>

    <li class="di_1ji_wu_xu_lie_biao">若<em class="calibre8">P</em><sub class="calibre20">nt</sub> &lt; <em class="calibre8">C</em><sub class="calibre20">nt</sub>，则有部分消费者线程分配不到分区，这导致分配不到分区的消费者线程将收不到任何消息。</li>
  </ul>

  <p class="zw">鉴于以上规则，在实际应用时多线程模型下采取<em class="calibre8">P</em><sub class="calibre20">nt</sub>与<em class="calibre8">C</em><sub class="calibre20">nt</sub>相等的实现方式，如果对消息顺序没有要求的应用场景则另当别论。另外，分配关系并不是分配之后就固定不变，当增加分区或者消费者线程数发生变化时就会引起平衡操作，线程与分区分配关系就会进行重新分配。</p>

  <p class="zw">前面的实例都是基于订阅一个主题，其实订阅多主题的分配过程与其基本类似。现在我们将round-robin分配实例通过range分配策略进行分配，分配结果如图4-24所示。</p>

  <p class="tu"><img alt="" src="../images/00088.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图4-24　2个主题2个消费者线程的range策略分配结果</p>

  <h3 id="nav_point_97" class="calibre9">4.4.8　消费者平衡过程</h3>

  <p class="zw">Kafka消费者平衡是指消费者重新加入消费组，并重新分配分区给消费者的过程。在以下几种情况下会引起消费者平衡操作。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">新的消费者加入消费组。</li>

    <li class="di_1ji_wu_xu_lie_biao">当前消费者从消费组退出。这里的退出包括异常退出和消费者正常关闭。</li>

    <li class="di_1ji_wu_xu_lie_biao">消费者取消对某个主题的订阅。</li>

    <li class="di_1ji_wu_xu_lie_biao">订阅主题的分区增加。</li>

    <li class="di_1ji_wu_xu_lie_biao">代理宕机新的协调器当选。</li>

    <li class="di_1ji_wu_xu_lie_biao">当消费者在${session.timeout.ms}毫秒内还没发送心跳请求，组协调器认为消费者已退出。</li>
  </ul>

  <p class="zw">消费者自动平衡操作提供了消费组的高可用性、可扩展性，这样当我们增加或是减少消费者时，无需关注消费者与分区的分配关系。只是在平衡操作时，由于要给消费者重新分配分区，所以会出现在一个短暂时间内消费者不能拉取消息。消费者平衡操作过程就是消费者重新加入消费组，然后由GroupCoordinator选出一个Leader消费者，由Leader消费者根据各消费者支持的分区分配策略制定分区分配方案，然后在SyncGroupRequest请求时Leader消费者将分区分配方案上传给GroupCoordinaotor，Follower消费者在SyncGroupRequest请求响应时会收到GroupCoordinator转发的分区分配方案，这样各消费者就会得到自己应该消费的分区。</p>

  <p class="zw">消费者平衡操作过程不再进行深入代码层面的分析，平衡操作各消费者重新加入消费组的过程请参考3.3.2节的相关介绍。</p>

  

  </div>

  
  <div class="calibreToc">
    <h2><a href="../../jhnii3.html"> Table of contents</a></h2>
     <div>
  <ul>
    <li>
      <a href="part0001.html#UGI0-b6aea6b975744e46b4d1346849966264">版权信息</a>
    </li>
    <li>
      <a href="part0002.html#1T140-b6aea6b975744e46b4d1346849966264">内容提要</a>
    </li>
    <li>
      <a href="part0003_split_000.html#2RHM0-b6aea6b975744e46b4d1346849966264">前言</a>
    </li>
    <li>
      <a href="part0004_split_000.html#3Q280-b6aea6b975744e46b4d1346849966264">第1章 Kafka简介</a>
      <ul>
        <li>
          <a href="part0004_split_001.html">1.1 Kafka背景</a>
        </li>
        <li>
          <a href="part0004_split_002.html">1.2 Kafka基本结构</a>
        </li>
        <li>
          <a href="part0004_split_003.html">1.3 Kafka基本概念</a>
        </li>
        <li>
          <a href="part0004_split_004.html">1.4 Kafka设计概述</a>
          <ul>
            <li>
              <a href="part0004_split_004.html#nav_point_13">1.4.1 Kafka设计动机</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_14">1.4.2 Kafka特性</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_15">1.4.3 Kafka应用场景</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0004_split_005.html">1.5 本书导读</a>
        </li>
        <li>
          <a href="part0004_split_006.html">1.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0005_split_000.html#4OIQ0-b6aea6b975744e46b4d1346849966264">第2章 Kafka安装配置</a>
      <ul>
        <li>
          <a href="part0005_split_001.html">2.1 基础环境配置</a>
          <ul>
            <li>
              <a href="part0005_split_001.html#nav_point_20">2.1.1 JDK安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_21">2.1.2 SSH安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_22">2.1.3 ZooKeeper环境</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_002.html">2.2 Kafka单机环境部署</a>
          <ul>
            <li>
              <a href="part0005_split_002.html#nav_point_24">2.2.1 Windows环境安装Kafka</a>
            </li>
            <li>
              <a href="part0005_split_002.html#nav_point_25">2.2.2 Linux环境安装Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_003.html">2.3 Kafka伪分布式环境部署</a>
        </li>
        <li>
          <a href="part0005_split_004.html">2.4 Kafka集群环境部署</a>
        </li>
        <li>
          <a href="part0005_split_005.html">2.5 Kafka Manager安装</a>
        </li>
        <li>
          <a href="part0005_split_006.html">2.6 Kafka源码编译</a>
          <ul>
            <li>
              <a href="part0005_split_006.html#nav_point_30">2.6.1 Scala安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_31">2.6.2 Gradle安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_32">2.6.3 Kafka源码编译</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_33">2.6.4 Kafka导入Eclipse</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_007.html">2.7 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0006_split_000.html#5N3C0-b6aea6b975744e46b4d1346849966264">第3章 Kafka核心组件</a>
      <ul>
        <li>
          <a href="part0006_split_001.html">3.1 延迟操作组件</a>
          <ul>
            <li>
              <a href="part0006_split_001.html#nav_point_37">3.1.1 DelayedOperation</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_38">3.1.2 DelayedOperationPurgatory</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_39">3.1.3 DelayedProduce</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_40">3.1.4 DelayedFetch</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_41">3.1.5 DelayedJoin</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_42">3.1.6 DelayedHeartbeat</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_43">3.1.7 DelayedCreateTopics</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_002.html">3.2 控制器</a>
          <ul>
            <li>
              <a href="part0006_split_002.html#nav_point_45">3.2.1 控制器初始化</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_46">3.2.2 控制器选举过程</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_47">3.2.3 故障转移</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_48">3.2.4 代理上线与下线</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_49">3.2.5 主题管理</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_50">3.2.6 分区管理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_003.html">3.3 协调器</a>
          <ul>
            <li>
              <a href="part0006_split_003.html#nav_point_52">3.3.1 消费者协调器</a>
            </li>
            <li>
              <a href="part0006_split_003.html#nav_point_53">3.3.2 组协调器</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_004.html">3.4 网络通信服务</a>
          <ul>
            <li>
              <a href="part0006_split_004.html#nav_point_55">3.4.1 Acceptor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_56">3.4.2 Processor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_57">3.4.3 RequestChannel</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_58">3.4.4 SocketServer启动过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_005.html">3.5 日志管理器</a>
          <ul>
            <li>
              <a href="part0006_split_005.html#nav_point_60">3.5.1 Kafka日志结构</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_61">3.5.2 日志管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_62">3.5.3 日志加载及恢复</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_63">3.5.4 日志清理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_006.html">3.6 副本管理器</a>
          <ul>
            <li>
              <a href="part0006_split_006.html#nav_point_65">3.6.1 分区</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_66">3.6.2 副本</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_67">3.6.3 副本管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_68">3.6.4 副本过期检查</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_69">3.6.5 追加消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_70">3.6.6 拉取消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_71">3.6.7 副本同步过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_72">3.6.8 副本角色转换</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_73">3.6.9 关闭副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_007.html">3.7 Handler</a>
        </li>
        <li>
          <a href="part0006_split_008.html">3.8 动态配置管理器</a>
        </li>
        <li>
          <a href="part0006_split_009.html">3.9 代理健康检测</a>
        </li>
        <li>
          <a href="part0006_split_010.html">3.10 Kafka内部监控</a>
        </li>
        <li>
          <a href="part0006_split_011.html">3.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0007_split_000.html#6LJU0-b6aea6b975744e46b4d1346849966264">第4章 Kafka核心流程分析</a>
      <ul>
        <li>
          <a href="part0007_split_001.html">4.1 KafkaServer启动流程分析</a>
        </li>
        <li>
          <a href="part0007_split_002.html">4.2 创建主题流程分析</a>
          <ul>
            <li>
              <a href="part0007_split_002.html#nav_point_82">4.2.1 客户端创建主题</a>
            </li>
            <li>
              <a href="part0007_split_002.html#nav_point_83">4.2.2 分区副本分配</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_003.html">4.3 生产者</a>
          <ul>
            <li>
              <a href="part0007_split_003.html#nav_point_85">4.3.1 Eclipse运行生产者源码</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_86">4.3.2 生产者重要配置说明</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_87">4.3.3 OldProducer执行流程</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_88">4.3.4 KafkaProducer实现原理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_004.html">4.4 消费者</a>
          <ul>
            <li>
              <a href="part0007_split_004.html#nav_point_90">4.4.1 旧版消费者</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_91">4.4.2 KafkaConsumer初始化</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_92">4.4.3 消费订阅</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_93">4.4.4 消费消息</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_94">4.4.5 消费偏移量提交</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_95">4.4.6 心跳探测</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_96">4.4.7 分区数与消费者线程的关系</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_97">4.4.8 消费者平衡过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_005.html">4.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0008_split_000.html#7K4G0-b6aea6b975744e46b4d1346849966264">第5章 Kafka基本操作实战</a>
      <ul>
        <li>
          <a href="part0008_split_001.html">5.1 KafkaServer管理</a>
          <ul>
            <li>
              <a href="part0008_split_001.html#nav_point_101">5.1.1 启动Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_102">5.1.2 启动Kafka集群</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_103">5.1.3 关闭Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_104">5.1.4 关闭Kafka集群</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_002.html">5.2 主题管理</a>
          <ul>
            <li>
              <a href="part0008_split_002.html#nav_point_106">5.2.1 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_107">5.2.2 删除主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_108">5.2.3 查看主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_109">5.2.4 修改主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_003.html">5.3 生产者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_003.html#nav_point_111">5.3.1 启动生产者</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_112">5.3.2 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_113">5.3.3 查看消息</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_114">5.3.4 生产者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_004.html">5.4 消费者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_004.html#nav_point_116">5.4.1 消费消息</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_117">5.4.2 单播与多播</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_118">5.4.3 查看消费偏移量</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_119">5.4.4 消费者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_005.html">5.5 配置管理</a>
          <ul>
            <li>
              <a href="part0008_split_005.html#nav_point_121">5.5.1 主题级别配置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_122">5.5.2 代理级别设置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_123">5.5.3 客户端/用户级别配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_006.html">5.6 分区操作</a>
          <ul>
            <li>
              <a href="part0008_split_006.html#nav_point_125">5.6.1 分区Leader平衡</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_126">5.6.2 分区迁移</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_127">5.6.3 增加分区</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_128">5.6.4 增加副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_007.html">5.7 连接器基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_007.html#nav_point_130">5.7.1 独立模式</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_131">5.7.2 REST风格API应用</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_132">5.7.3 分布式模式</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_008.html">5.8 Kafka Manager应用</a>
        </li>
        <li>
          <a href="part0008_split_009.html">5.9 Kafka安全机制</a>
          <ul>
            <li>
              <a href="part0008_split_009.html#nav_point_135">5.9.1 利用SASL/PLAIN进行身份认证</a>
            </li>
            <li>
              <a href="part0008_split_009.html#nav_point_136">5.9.2 权限控制</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_010.html">5.10 镜像操作</a>
        </li>
        <li>
          <a href="part0008_split_011.html">5.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0009_split_000.html#8IL20-b6aea6b975744e46b4d1346849966264">第6章 Kafka API编程实战</a>
      <ul>
        <li>
          <a href="part0009_split_001.html">6.1 主题管理</a>
          <ul>
            <li>
              <a href="part0009_split_001.html#nav_point_141">6.1.1 创建主题</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_142">6.1.2 修改主题级别配置</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_143">6.1.3 增加分区</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_144">6.1.4 分区副本重分配</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_145">6.1.5 删除主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_002.html">6.2 生产者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_002.html#nav_point_147">6.2.1 单线程生产者</a>
            </li>
            <li>
              <a href="part0009_split_002.html#nav_point_148">6.2.2 多线程生产者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_003.html">6.3 消费者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_003.html#nav_point_150">6.3.1 旧版消费者API应用</a>
            </li>
            <li>
              <a href="part0009_split_003.html#nav_point_151">6.3.2 新版消费者API应用</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_004.html">6.4 自定义组件实现</a>
          <ul>
            <li>
              <a href="part0009_split_004.html#nav_point_153">6.4.1 分区器</a>
            </li>
            <li>
              <a href="part0009_split_004.html#nav_point_154">6.4.2 序列化与反序列化</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_005.html">6.5 Spring与Kafka整合应用</a>
          <ul>
            <li>
              <a href="part0009_split_005.html#nav_point_156">6.5.1 生产者</a>
            </li>
            <li>
              <a href="part0009_split_005.html#nav_point_157">6.5.2 消费者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_006.html">6.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0010_split_000.html#9H5K0-b6aea6b975744e46b4d1346849966264">第7章 Kafka Streams</a>
      <ul>
        <li>
          <a href="part0010_split_001.html">7.1 Kafka Streams简介</a>
        </li>
        <li>
          <a href="part0010_split_002.html">7.2 Kafka Streams基本概念</a>
          <ul>
            <li>
              <a href="part0010_split_002.html#nav_point_162">7.2.1 流</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_163">7.2.2 流处理器</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_164">7.2.3 处理器拓扑</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_165">7.2.4 时间</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_166">7.2.5 状态</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_167">7.2.6 KStream和KTable</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_168">7.2.7 窗口</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_003.html">7.3 Kafka Streams API介绍</a>
          <ul>
            <li>
              <a href="part0010_split_003.html#nav_point_170">7.3.1 KStream与KTable</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_171">7.3.2 窗口操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_172">7.3.3 连接操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_173">7.3.4 变换操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_174">7.3.5 聚合操作</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_004.html">7.4 接口恶意访问自动检测</a>
          <ul>
            <li>
              <a href="part0010_split_004.html#nav_point_176">7.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0010_split_004.html#nav_point_177">7.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_005.html">7.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0011_split_000.html#AFM60-b6aea6b975744e46b4d1346849966264">第8章 Kafka数据采集应用</a>
      <ul>
        <li>
          <a href="part0011_split_001.html">8.1 Log4j集成Kafka应用</a>
          <ul>
            <li>
              <a href="part0011_split_001.html#nav_point_181">8.1.1 应用描述</a>
            </li>
            <li>
              <a href="part0011_split_001.html#nav_point_182">8.1.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_002.html">8.2 Kafka与Flume整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_002.html#nav_point_184">8.2.1 Flume简介</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_185">8.2.2 Flume与Kafka比较</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_186">8.2.3 Flume的安装配置</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_187">8.2.4 Flume采集日志写入Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_003.html">8.3 Kafka与Flume和HDFS整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_003.html#nav_point_189">8.3.1 Hadoop安装配置</a>
            </li>
            <li>
              <a href="part0011_split_003.html#nav_point_190">8.3.2 Flume采集Kafka消息写入HDFS</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_004.html">8.4 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0012_split_000.html#BE6O0-b6aea6b975744e46b4d1346849966264">第9章 Kafka与ELK整合应用</a>
      <ul>
        <li>
          <a href="part0012_split_001.html">9.1 ELK环境搭建</a>
          <ul>
            <li>
              <a href="part0012_split_001.html#nav_point_194">9.1.1 Elasticsearch安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_195">9.1.2 Logstash安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_196">9.1.3 Kibana安装配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_002.html">9.2 Kafka与Logstash整合</a>
          <ul>
            <li>
              <a href="part0012_split_002.html#nav_point_198">9.2.1 Logstash收集日志到Kafka</a>
            </li>
            <li>
              <a href="part0012_split_002.html#nav_point_199">9.2.2 Logstash从Kafka消费日志</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_003.html">9.3 日志采集分析系统</a>
          <ul>
            <li>
              <a href="part0012_split_003.html#nav_point_201">9.3.1 Flume采集日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_202">9.3.2 Logstash拉取日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_203">9.3.3 Kibana日志展示</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_004.html">9.4 服务器性能监控系统</a>
          <ul>
            <li>
              <a href="part0012_split_004.html#nav_point_205">9.4.1 Metricbeat安装</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_206">9.4.2 采集信息存储到Elasticsearch</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_207">9.4.3 加载beats-dashboards</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_208">9.4.4 服务器性能监控系统具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_005.html">9.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0013_split_000.html#CCNA0-b6aea6b975744e46b4d1346849966264">第10章 Kafka与Spark整合应用</a>
      <ul>
        <li>
          <a href="part0013_split_001.html">10.1 Spark简介</a>
        </li>
        <li>
          <a href="part0013_split_002.html">10.2 Spark基本操作</a>
          <ul>
            <li>
              <a href="part0013_split_002.html#nav_point_213">10.2.1 Spark安装</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_214">10.2.2 Spark shell应用</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_215">10.2.3 spark-submit提交作业</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_003.html">10.3 Spark在智能投顾领域应用</a>
          <ul>
            <li>
              <a href="part0013_split_003.html#nav_point_217">10.3.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_003.html#nav_point_218">10.3.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_004.html">10.4 热搜词统计</a>
          <ul>
            <li>
              <a href="part0013_split_004.html#nav_point_220">10.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_004.html#nav_point_221">10.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_005.html">10.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0014_split_000.html#DB7S0-b6aea6b975744e46b4d1346849966264">欢迎来到异步社区！</a>
    </li>
  </ul>
</div>


  </div>
  

  <div class="calibreEbNav">
    
      <a href="part0007_split_003.html" class="calibreAPrev">previous page</a>
    

    <a href="../../jhnii3.html" class="calibreAHome"> start</a>

    
      <a href="part0007_split_005.html" class="calibreANext"> next page</a>
    
  </div>

</div>

</body>
</html>
