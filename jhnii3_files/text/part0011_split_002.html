<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>

  


<link href="../calibreHtmlOutBasicCss.css" type="text/css" rel="stylesheet" />

</head>
<body>

<div class="calibreMeta">
  <div class="calibreMetaTitle">
  
  
    
    <h1>
      <a href="../../jhnii3.html">Kafka入门与实践
</a>
    </h1>
    
    
  
  </div>
  <div class="calibreMetaAuthor">
    牟大恩

  </div>
</div>

<div class="calibreMain">

  <div class="calibreEbookContent">
    
      <div class="calibreEbNavTop">
        
          <a href="part0011_split_001.html" class="calibreAPrev">previous page</a>
        

        
          <a href="part0011_split_003.html" class="calibreANext"> next page</a>
        
      </div>
    

    
<h2 id="nav_point_183" class="sigil_not_in_toc">8.2　Kafka与Flume整合应用</h2>

  <p class="zw">8.1节介绍了通过kafka-log4j-appender将应用程序的日志直接写入到Kafka，这种方式虽然简单，但由于应用程序依赖于Kafka运行环境，因此存在一定的不足。</p>

  <p class="zw">通常做法是：应用程序将日志写入本地，然后通过日志采集工具将本地日志同步到远程服务器，而Flume就是最常用数据采集工具之一。现在引入Flume，通过Flume将应用程序产生的日志同步到Kafka，基本系统结构如图8-3所示。</p>

  <p class="tu"><img alt="" src="../images/00135.jpeg" class="calibre7"/></p>

  <p class="tu_ti">图8-3　Flume采集应用日志写入Kafka系统结构</p>

  <h3 id="nav_point_184" class="calibre9">8.2.1　Flume简介</h3>

  <p class="zw">Flume是由Cloudera公司开发的一个高可用、高可靠、分布式海量日志收集、聚合和传输的系统，目前已是Apache下的一个顶级项目。Flume提供了很多与之对接的组件，可以很方便地进行数据传输。编写本书时，Flume的最新版本为1.7.0。Flume 1.x版本相对Flume 0.9.x版本被称为Flume next generation，简称为Flume NG。本书所使用的Flume版本为Flume NG 1.7.0版本。</p>

  <p class="zw">Flume NG主要由事件源（Souce）、通道（Channel）和接收器（Sink）3个组件构成，由这3个组件组成的一个代理Agent，也就是通常所说的Flume代理，一个Flume代理可能包括多个源、通道和接收器。一个基本的Flume数据流模型如图8-4所示。</p>

  <p class="tu"><img alt="" src="../images/00136.gif" class="calibre7"/></p>

  <p class="tu_ti">图8-4　Flume NG基本数据流模型</p>

  <p class="zw">Flume将一个具有有效负荷的字节数据流和可选的字符串属性集称为事件（Event），一个事件带有一个可选的消息头，消息头可用于路由判定或者一些用于消息标识的信息，事件是Flume数据传输的基本单位。</p>

  <p class="zw">事件源就是负责从数据源采集数据将事件发送到一到多个通道中，是数据流入的入口。常见事件源有文件、网络、数据库、Kafka等。</p>

  <p class="zw">通道负责将事件源流入的数据进行聚合、暂存，通常数据在通道停留的时间不会太长，很快就会被接收器消费，它是位于事件源与接收器之间的构件。通道主要包括非持久化通道（如内存通道Memory Channel）与持久化通道（如文件通道File Channel、数据库JDBC Channel）。</p>

  <p class="zw">接收器负责从通道消费数据，将数据转移到其他存储系统，例如，将数据存储到文件、数据库、HDFS、Kafka、HBase等。</p>

  <p class="zw">同时，Flume还提供了拦截器的功能，我们可以在源之后、接收器之前链接0个或多个拦截器，与Spring AOP作用类似，可以通过拦截器在数据流入通道之前或数据流出通道之后对数据进行处理。</p>

  <p class="zw">Flume提供了负载均衡（load_balance）和故障转移（failover）功能。负载均衡提供了轮询（round_robin）和随机（random）两种策略，可以通过processor.selector属性指定。故障转移是通过为接收器Processor配置维护一个优先级列表，以保证每一个有效事件都能够被处理。通过processor.type来指定是故障转移还是负载均衡，这里我们不进行深入介绍。</p>

  <p class="zw">Flume内置了很多的源组件和接收器组件，通过相关组件可以很方便地实现数据的传输，同时Flume也提供了很多自定义组件的接口，在本书我们也不再介绍。</p>

  <h3 id="nav_point_185" class="calibre9">8.2.2　Flume与Kafka比较</h3>

  <p class="zw">在介绍Flume的基本概念时提到了源（Source）和接收器（Sink），这两个组件在介绍Kafka连接器时也曾提到，在数据采取传输方面Flume和Kafka实现原理很类似。然而两个框架侧重点还是不同的。Kafka追求的是高吞吐量、高负载的消息系统及数据流存储平台，同时提供了对流实时计算功能，而Flume追求的是数据来源的多样性、数据流向的多样性，Flume不提供数据存储功能而侧重于数据传输。两者的对比关系如表8-1所示。</p>

  <p class="biao_ti">表8-1　Kafka与Flume对比</p>

  <table border="1" width="90%" class="calibre11">
    <thead class="calibre12">
      <tr class="calibre13">
        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">对比项</p>
        </th>

        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">Kafka</p>
        </th>

        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">Flume</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre15">
      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">功能</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">侧重于数据存储，流数据实时处理</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">侧重于数据采取传输</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">开发语言</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">Scala和Java</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">Java</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">数据持久化</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">提供数据持久化</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">不直接提供数据持久化</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">副本机制</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">多副本机制</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">无副本机制</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">负载均衡</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">支持</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">支持</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">故障转移</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">支持</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">支持</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">可扩展性</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">良好</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">良好</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">容错机制</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">多副本机制以保证容错机制</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">通过维护一个接收器优先级列表</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">数据预处理</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">由外部应用程序处理</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">通过拦截器处理</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">传输方式</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">主动轮询拉取</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">主动轮询拉取与事件驱动</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="zw">一般情况下，如果是为了追求高吞吐量、数据存储或用于实时计算，可以选择Kafka；如果数据来源和数据流向较多，或者需要将数据进行简单处理，可以选择Flume。然而，在有些应用场景将两者结合起来使用更方便、性能更好。例如，在程序分布式部署时，可以为每台应用程序服务器部署一个Flume NG，通过Flume将数据传输给Kafka，因为Flume部署较Kafka简单，相对轻量级。</p>

  <h3 id="nav_point_186" class="calibre9">8.2.3　Flume的安装配置</h3>

  <p class="zw">在Flume官方网站http://flume.apache.org/download.html下载二进制格式的安装包，这里下载的Flume版本为apache-flume-1.7.0-bin.tar，将Flume安装文件上传至服务器进行解压，这里记Flume的安装路径为FLUME_HOME，我们只介绍Flume单节点的安装，在本书涉及Flume的应用也是基于Flume单节点环境的。解压之后执行以下步骤进行安装配置。</p>

  <p class="zw">（1）<strong class="calibre1">修改flume-env.sh</strong>。Flume运行在JVM之上，因此在安装Flume之前，要确保系统已安装了JDK。进入$FLUME_HOME/conf目录，在该目录下有一个Flume环境配置文件flume-env.sh.template，对于单节点的Flume安装，我们只需修改环境配置文件即可。</p>

  <p class="zw">首先通过cp命令将flume-env.sh.template复制一份并命名为flume-evn.sh，然后通过vi命令打开flume-env.sh文件，在该文件中加入Java安装路径。具体执行命令如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">cp flume-env.sh.template fluem-env.sh       # 复制一份Flume环境变量配置
vi flume-env.sh                             # vi打开文件编辑
export JAVA_HOME=/usr/local/software/Java/jdk1.8.0_111   # 添加本机Java安装路径
:wq                                         # 保存修改</code></pre>

  <p class="zw">（2）<strong class="calibre1">设置系统环境变量</strong>。将flume安装路径加入到系统环境变量中，只需在/etc/profile文件中加入Flume的安装路径，然后将Flume的bin目录添加到系统Path中，执行以下命令：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">vi /etc/profile                              # vi打开/etc/profile文件
export FLUME_HOME=/usr/local/software/flume/flume-1.7.0  # 定义Flume环境变量名
export PATH=$PATH: $FLUME_HOME/bin           # 将Flume的bin目录添加至系统Path中
:wq                                          # 保存修改
source /etc/profile                          # 使修改立即生效</code></pre>

  <p class="zw">（3）<strong class="calibre1">验证</strong>。在$FLUME_HOME/conf目录下有一个Flume采集数据的Source及Sink配置模板文件flume-conf.properties.template，Flume自带了一个用于生成测试数据的Source，通道为内存，接收器为Logger，即将数据以日志形式输出。运行以下命令启动Flume，该启动命令参数说明如表8-2所示。</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">flume-ng agent --conf /usr/local/software/flume/flume-1.7.0/conf  --conf-file conf/flume-conf.properties.template  --name agent -Dflume.root.logger=INFO,console</code></pre>

  <p class="biao_ti">表8-2　Flume启动命令参数说明</p>

  <table border="1" width="90%" class="calibre11">
    <thead class="calibre12">
      <tr class="calibre13">
        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">参数名</p>
        </th>

        <th class="calibre14">
          <p class="biao_tou_dan_yuan_ge">参数说明</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre15">
      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">agent</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">指定以agent的角色启动，另外一个角色为avro-client</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">conf或c</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">指定配置源和接收器配置文件的绝对路径，不包括配置文件名</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">config-file或f</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">指定配置源和接收器配置文件的相对路径，相对于执行该命令的目录</p>
        </td>
      </tr>

      <tr class="calibre17">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">name或n</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">指定agent的名称</p>
        </td>
      </tr>

      <tr class="calibre13">
        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">D</p>
        </td>

        <td class="calibre16">
          <p class="biao_tou_dan_yuan_ge">用-D后接键值对，指定Java相关的配置，如本例指定将等级为info的日志信息输出到控制台</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="zw">运行以上启动Flume agent命令需要保证--conf和--config-file正确配置，否则会出现以下警告信息而导致启动失败：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">log4j:WARN No appenders could be found for logger (org.apache.flume.node.Application).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</code></pre>

  <h3 id="nav_point_187" class="calibre9">8.2.4　Flume采集日志写入Kafka</h3>

  <p class="zw">现在通过Flume将日志文件的数据同步到Kafka的实例详细介绍Flume采集数据的基本配置。创建一个flume-kafka.properties文件，然后按以下步骤完成Flume采集数据写入Kafka的相关配置。</p>

  <p class="zw">首先指定源、接收器和通道的名称，配置如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">agent.sources = sc             # 指定源名称
agent.sinks = sk               # 指定接收器名称
agent.channels = chl           # 指定道通名称</code></pre>

  <p class="zw">以上配置，agent表示代理的名称，代理名称可以为任意字符串，当有多个代理时要保证代理名称唯一。</p>

  <p class="zw">接着配置源，本例是Flume监听tail命令打开的/opt/data/flume/test.log文件内容，主要配置信息如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">agent.sources.sc.type = exec         # 指定源类型为Linux命令
agent.sources.sc.channels = chl      # 绑定通道，指定源将事件传递的通道，可以指定多个通道
agent.sources.sc.command =tail -f /opt/data/flume/test.log  # 以tail命令打开文件输出流
agent.sources.sc.fileHeader = false  # 指定事件不包括头信息</code></pre>

  <p class="zw">然后配置通道信息，本实例采用内存通道，内存通道配置信息如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">agent.channels.chl.type = memory               # 指定通道类型
agent.channels.chl.capacity = 1000             # 在通道中停留的最大事件数
agent.channels.chl.transactionCapacity = 1000  # 每次从源拉取的事件数及给接收器的事件数</code></pre>

  <p class="zw">最后配置接收器，接收器从通道获取信息写入到Kafka，配置信息如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10"># 接收器类型
agent.sinks.sk.type = org.apache.flume.sink.kafka.KafkaSink
# 绑定通道，指定接收器读取数据的通道
agent.sinks.sk.channel = chl
agent.sinks.sk.kafka.bootstrap.servers=server-1:9092,server-2:9092,server-3:9092
# 指定写入Kafka的主题
agent.sinks.sk.kafka.topic=flume-kafka
# 指定序列化类
agent.sinks.sk.serializer.class=kafka.serializer.StringEncoder
# 生产者acks方式
agent.sinks.sk.kafka.producer.acks = 1
# 指定字符编码
agent.sinks.sk.custom.encoding=UTF-8</code></pre>

  <p class="zw">配置接收器类型之所以能指定为KafkaSink，是因为在$FLUME_HOME/lib目录自带了与Kafka集成的flume-ng-kafka-sink-1.7.0.jar文件。在lib目录下还可以看到Flume从Kafka采集数据的flume-kafka-source-1.7.0.jar文件，以及Flume采集数据写入HBase和HDFS的Sink jar文件。同时，还可以指定生产者相关的其他配置，在生产者相关的配置属性名前加上“kafka.producer.”前缀即可。至此，Flume采集文件写入Kafka的配置介绍完毕，在启动Flume agent之前，先创建主题“flume-kafka”，命令如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">kafka-topics.sh --zookeeper server-1:2181,server-2:2181,server-3:2181 --create --topic flume-kafka --partitions 3 --replication-factor 1</code></pre>

  <p class="zw">启动Flume，为了在控制台打印启动日志，启动命令增加了--Dflume.root.logger=INFO,console配置，启动本例配置的Flume agent命令如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">flume-ng agent --conf /usr/local/software/flume/flume-1.7.0/conf  --conf-file conf/flume-kafka.properties  --name agent  -Dflume.root.logger=INFO,console</code></pre>

  <p class="zw">为了验证日志是否成功写入到Kafka，我们启动一个消费者消费“flume-kafka”主题，然后在控制台执行echo指令写入一条数据到/opt/data/flume/test.log文件，命令如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">echo "flume实时从文件采集数据写入Kafka" &gt;/opt/data/flume/test.log</code></pre>

  <p class="zw">在控制台可以看到消费者及时收到Flume采集的数据，如图8-5所示。</p>

  <p class="tu"><img alt="" src="../images/00137.gif" class="calibre7"/></p>

  <p class="tu_ti">图8-5　Flume采集数据写入Kafka的效果</p>

  <p class="zw">至此，Flume采集数据写入Kafka的相关操作介绍完毕。</p>

  

  </div>

  
  <div class="calibreToc">
    <h2><a href="../../jhnii3.html"> Table of contents</a></h2>
     <div>
  <ul>
    <li>
      <a href="part0001.html#UGI0-b6aea6b975744e46b4d1346849966264">版权信息</a>
    </li>
    <li>
      <a href="part0002.html#1T140-b6aea6b975744e46b4d1346849966264">内容提要</a>
    </li>
    <li>
      <a href="part0003_split_000.html#2RHM0-b6aea6b975744e46b4d1346849966264">前言</a>
    </li>
    <li>
      <a href="part0004_split_000.html#3Q280-b6aea6b975744e46b4d1346849966264">第1章 Kafka简介</a>
      <ul>
        <li>
          <a href="part0004_split_001.html">1.1 Kafka背景</a>
        </li>
        <li>
          <a href="part0004_split_002.html">1.2 Kafka基本结构</a>
        </li>
        <li>
          <a href="part0004_split_003.html">1.3 Kafka基本概念</a>
        </li>
        <li>
          <a href="part0004_split_004.html">1.4 Kafka设计概述</a>
          <ul>
            <li>
              <a href="part0004_split_004.html#nav_point_13">1.4.1 Kafka设计动机</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_14">1.4.2 Kafka特性</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_15">1.4.3 Kafka应用场景</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0004_split_005.html">1.5 本书导读</a>
        </li>
        <li>
          <a href="part0004_split_006.html">1.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0005_split_000.html#4OIQ0-b6aea6b975744e46b4d1346849966264">第2章 Kafka安装配置</a>
      <ul>
        <li>
          <a href="part0005_split_001.html">2.1 基础环境配置</a>
          <ul>
            <li>
              <a href="part0005_split_001.html#nav_point_20">2.1.1 JDK安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_21">2.1.2 SSH安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_22">2.1.3 ZooKeeper环境</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_002.html">2.2 Kafka单机环境部署</a>
          <ul>
            <li>
              <a href="part0005_split_002.html#nav_point_24">2.2.1 Windows环境安装Kafka</a>
            </li>
            <li>
              <a href="part0005_split_002.html#nav_point_25">2.2.2 Linux环境安装Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_003.html">2.3 Kafka伪分布式环境部署</a>
        </li>
        <li>
          <a href="part0005_split_004.html">2.4 Kafka集群环境部署</a>
        </li>
        <li>
          <a href="part0005_split_005.html">2.5 Kafka Manager安装</a>
        </li>
        <li>
          <a href="part0005_split_006.html">2.6 Kafka源码编译</a>
          <ul>
            <li>
              <a href="part0005_split_006.html#nav_point_30">2.6.1 Scala安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_31">2.6.2 Gradle安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_32">2.6.3 Kafka源码编译</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_33">2.6.4 Kafka导入Eclipse</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_007.html">2.7 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0006_split_000.html#5N3C0-b6aea6b975744e46b4d1346849966264">第3章 Kafka核心组件</a>
      <ul>
        <li>
          <a href="part0006_split_001.html">3.1 延迟操作组件</a>
          <ul>
            <li>
              <a href="part0006_split_001.html#nav_point_37">3.1.1 DelayedOperation</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_38">3.1.2 DelayedOperationPurgatory</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_39">3.1.3 DelayedProduce</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_40">3.1.4 DelayedFetch</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_41">3.1.5 DelayedJoin</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_42">3.1.6 DelayedHeartbeat</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_43">3.1.7 DelayedCreateTopics</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_002.html">3.2 控制器</a>
          <ul>
            <li>
              <a href="part0006_split_002.html#nav_point_45">3.2.1 控制器初始化</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_46">3.2.2 控制器选举过程</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_47">3.2.3 故障转移</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_48">3.2.4 代理上线与下线</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_49">3.2.5 主题管理</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_50">3.2.6 分区管理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_003.html">3.3 协调器</a>
          <ul>
            <li>
              <a href="part0006_split_003.html#nav_point_52">3.3.1 消费者协调器</a>
            </li>
            <li>
              <a href="part0006_split_003.html#nav_point_53">3.3.2 组协调器</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_004.html">3.4 网络通信服务</a>
          <ul>
            <li>
              <a href="part0006_split_004.html#nav_point_55">3.4.1 Acceptor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_56">3.4.2 Processor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_57">3.4.3 RequestChannel</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_58">3.4.4 SocketServer启动过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_005.html">3.5 日志管理器</a>
          <ul>
            <li>
              <a href="part0006_split_005.html#nav_point_60">3.5.1 Kafka日志结构</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_61">3.5.2 日志管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_62">3.5.3 日志加载及恢复</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_63">3.5.4 日志清理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_006.html">3.6 副本管理器</a>
          <ul>
            <li>
              <a href="part0006_split_006.html#nav_point_65">3.6.1 分区</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_66">3.6.2 副本</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_67">3.6.3 副本管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_68">3.6.4 副本过期检查</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_69">3.6.5 追加消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_70">3.6.6 拉取消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_71">3.6.7 副本同步过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_72">3.6.8 副本角色转换</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_73">3.6.9 关闭副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_007.html">3.7 Handler</a>
        </li>
        <li>
          <a href="part0006_split_008.html">3.8 动态配置管理器</a>
        </li>
        <li>
          <a href="part0006_split_009.html">3.9 代理健康检测</a>
        </li>
        <li>
          <a href="part0006_split_010.html">3.10 Kafka内部监控</a>
        </li>
        <li>
          <a href="part0006_split_011.html">3.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0007_split_000.html#6LJU0-b6aea6b975744e46b4d1346849966264">第4章 Kafka核心流程分析</a>
      <ul>
        <li>
          <a href="part0007_split_001.html">4.1 KafkaServer启动流程分析</a>
        </li>
        <li>
          <a href="part0007_split_002.html">4.2 创建主题流程分析</a>
          <ul>
            <li>
              <a href="part0007_split_002.html#nav_point_82">4.2.1 客户端创建主题</a>
            </li>
            <li>
              <a href="part0007_split_002.html#nav_point_83">4.2.2 分区副本分配</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_003.html">4.3 生产者</a>
          <ul>
            <li>
              <a href="part0007_split_003.html#nav_point_85">4.3.1 Eclipse运行生产者源码</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_86">4.3.2 生产者重要配置说明</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_87">4.3.3 OldProducer执行流程</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_88">4.3.4 KafkaProducer实现原理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_004.html">4.4 消费者</a>
          <ul>
            <li>
              <a href="part0007_split_004.html#nav_point_90">4.4.1 旧版消费者</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_91">4.4.2 KafkaConsumer初始化</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_92">4.4.3 消费订阅</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_93">4.4.4 消费消息</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_94">4.4.5 消费偏移量提交</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_95">4.4.6 心跳探测</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_96">4.4.7 分区数与消费者线程的关系</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_97">4.4.8 消费者平衡过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_005.html">4.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0008_split_000.html#7K4G0-b6aea6b975744e46b4d1346849966264">第5章 Kafka基本操作实战</a>
      <ul>
        <li>
          <a href="part0008_split_001.html">5.1 KafkaServer管理</a>
          <ul>
            <li>
              <a href="part0008_split_001.html#nav_point_101">5.1.1 启动Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_102">5.1.2 启动Kafka集群</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_103">5.1.3 关闭Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_104">5.1.4 关闭Kafka集群</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_002.html">5.2 主题管理</a>
          <ul>
            <li>
              <a href="part0008_split_002.html#nav_point_106">5.2.1 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_107">5.2.2 删除主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_108">5.2.3 查看主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_109">5.2.4 修改主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_003.html">5.3 生产者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_003.html#nav_point_111">5.3.1 启动生产者</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_112">5.3.2 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_113">5.3.3 查看消息</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_114">5.3.4 生产者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_004.html">5.4 消费者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_004.html#nav_point_116">5.4.1 消费消息</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_117">5.4.2 单播与多播</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_118">5.4.3 查看消费偏移量</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_119">5.4.4 消费者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_005.html">5.5 配置管理</a>
          <ul>
            <li>
              <a href="part0008_split_005.html#nav_point_121">5.5.1 主题级别配置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_122">5.5.2 代理级别设置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_123">5.5.3 客户端/用户级别配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_006.html">5.6 分区操作</a>
          <ul>
            <li>
              <a href="part0008_split_006.html#nav_point_125">5.6.1 分区Leader平衡</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_126">5.6.2 分区迁移</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_127">5.6.3 增加分区</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_128">5.6.4 增加副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_007.html">5.7 连接器基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_007.html#nav_point_130">5.7.1 独立模式</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_131">5.7.2 REST风格API应用</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_132">5.7.3 分布式模式</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_008.html">5.8 Kafka Manager应用</a>
        </li>
        <li>
          <a href="part0008_split_009.html">5.9 Kafka安全机制</a>
          <ul>
            <li>
              <a href="part0008_split_009.html#nav_point_135">5.9.1 利用SASL/PLAIN进行身份认证</a>
            </li>
            <li>
              <a href="part0008_split_009.html#nav_point_136">5.9.2 权限控制</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_010.html">5.10 镜像操作</a>
        </li>
        <li>
          <a href="part0008_split_011.html">5.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0009_split_000.html#8IL20-b6aea6b975744e46b4d1346849966264">第6章 Kafka API编程实战</a>
      <ul>
        <li>
          <a href="part0009_split_001.html">6.1 主题管理</a>
          <ul>
            <li>
              <a href="part0009_split_001.html#nav_point_141">6.1.1 创建主题</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_142">6.1.2 修改主题级别配置</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_143">6.1.3 增加分区</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_144">6.1.4 分区副本重分配</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_145">6.1.5 删除主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_002.html">6.2 生产者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_002.html#nav_point_147">6.2.1 单线程生产者</a>
            </li>
            <li>
              <a href="part0009_split_002.html#nav_point_148">6.2.2 多线程生产者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_003.html">6.3 消费者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_003.html#nav_point_150">6.3.1 旧版消费者API应用</a>
            </li>
            <li>
              <a href="part0009_split_003.html#nav_point_151">6.3.2 新版消费者API应用</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_004.html">6.4 自定义组件实现</a>
          <ul>
            <li>
              <a href="part0009_split_004.html#nav_point_153">6.4.1 分区器</a>
            </li>
            <li>
              <a href="part0009_split_004.html#nav_point_154">6.4.2 序列化与反序列化</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_005.html">6.5 Spring与Kafka整合应用</a>
          <ul>
            <li>
              <a href="part0009_split_005.html#nav_point_156">6.5.1 生产者</a>
            </li>
            <li>
              <a href="part0009_split_005.html#nav_point_157">6.5.2 消费者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_006.html">6.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0010_split_000.html#9H5K0-b6aea6b975744e46b4d1346849966264">第7章 Kafka Streams</a>
      <ul>
        <li>
          <a href="part0010_split_001.html">7.1 Kafka Streams简介</a>
        </li>
        <li>
          <a href="part0010_split_002.html">7.2 Kafka Streams基本概念</a>
          <ul>
            <li>
              <a href="part0010_split_002.html#nav_point_162">7.2.1 流</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_163">7.2.2 流处理器</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_164">7.2.3 处理器拓扑</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_165">7.2.4 时间</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_166">7.2.5 状态</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_167">7.2.6 KStream和KTable</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_168">7.2.7 窗口</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_003.html">7.3 Kafka Streams API介绍</a>
          <ul>
            <li>
              <a href="part0010_split_003.html#nav_point_170">7.3.1 KStream与KTable</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_171">7.3.2 窗口操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_172">7.3.3 连接操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_173">7.3.4 变换操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_174">7.3.5 聚合操作</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_004.html">7.4 接口恶意访问自动检测</a>
          <ul>
            <li>
              <a href="part0010_split_004.html#nav_point_176">7.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0010_split_004.html#nav_point_177">7.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_005.html">7.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0011_split_000.html#AFM60-b6aea6b975744e46b4d1346849966264">第8章 Kafka数据采集应用</a>
      <ul>
        <li>
          <a href="part0011_split_001.html">8.1 Log4j集成Kafka应用</a>
          <ul>
            <li>
              <a href="part0011_split_001.html#nav_point_181">8.1.1 应用描述</a>
            </li>
            <li>
              <a href="part0011_split_001.html#nav_point_182">8.1.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_002.html">8.2 Kafka与Flume整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_002.html#nav_point_184">8.2.1 Flume简介</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_185">8.2.2 Flume与Kafka比较</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_186">8.2.3 Flume的安装配置</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_187">8.2.4 Flume采集日志写入Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_003.html">8.3 Kafka与Flume和HDFS整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_003.html#nav_point_189">8.3.1 Hadoop安装配置</a>
            </li>
            <li>
              <a href="part0011_split_003.html#nav_point_190">8.3.2 Flume采集Kafka消息写入HDFS</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_004.html">8.4 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0012_split_000.html#BE6O0-b6aea6b975744e46b4d1346849966264">第9章 Kafka与ELK整合应用</a>
      <ul>
        <li>
          <a href="part0012_split_001.html">9.1 ELK环境搭建</a>
          <ul>
            <li>
              <a href="part0012_split_001.html#nav_point_194">9.1.1 Elasticsearch安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_195">9.1.2 Logstash安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_196">9.1.3 Kibana安装配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_002.html">9.2 Kafka与Logstash整合</a>
          <ul>
            <li>
              <a href="part0012_split_002.html#nav_point_198">9.2.1 Logstash收集日志到Kafka</a>
            </li>
            <li>
              <a href="part0012_split_002.html#nav_point_199">9.2.2 Logstash从Kafka消费日志</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_003.html">9.3 日志采集分析系统</a>
          <ul>
            <li>
              <a href="part0012_split_003.html#nav_point_201">9.3.1 Flume采集日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_202">9.3.2 Logstash拉取日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_203">9.3.3 Kibana日志展示</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_004.html">9.4 服务器性能监控系统</a>
          <ul>
            <li>
              <a href="part0012_split_004.html#nav_point_205">9.4.1 Metricbeat安装</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_206">9.4.2 采集信息存储到Elasticsearch</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_207">9.4.3 加载beats-dashboards</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_208">9.4.4 服务器性能监控系统具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_005.html">9.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0013_split_000.html#CCNA0-b6aea6b975744e46b4d1346849966264">第10章 Kafka与Spark整合应用</a>
      <ul>
        <li>
          <a href="part0013_split_001.html">10.1 Spark简介</a>
        </li>
        <li>
          <a href="part0013_split_002.html">10.2 Spark基本操作</a>
          <ul>
            <li>
              <a href="part0013_split_002.html#nav_point_213">10.2.1 Spark安装</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_214">10.2.2 Spark shell应用</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_215">10.2.3 spark-submit提交作业</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_003.html">10.3 Spark在智能投顾领域应用</a>
          <ul>
            <li>
              <a href="part0013_split_003.html#nav_point_217">10.3.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_003.html#nav_point_218">10.3.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_004.html">10.4 热搜词统计</a>
          <ul>
            <li>
              <a href="part0013_split_004.html#nav_point_220">10.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_004.html#nav_point_221">10.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_005.html">10.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0014_split_000.html#DB7S0-b6aea6b975744e46b4d1346849966264">欢迎来到异步社区！</a>
    </li>
  </ul>
</div>


  </div>
  

  <div class="calibreEbNav">
    
      <a href="part0011_split_001.html" class="calibreAPrev">previous page</a>
    

    <a href="../../jhnii3.html" class="calibreAHome"> start</a>

    
      <a href="part0011_split_003.html" class="calibreANext"> next page</a>
    
  </div>

</div>

</body>
</html>
