<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>

  


<link href="../calibreHtmlOutBasicCss.css" type="text/css" rel="stylesheet" />

</head>
<body>

<div class="calibreMeta">
  <div class="calibreMetaTitle">
  
  
    
    <h1>
      <a href="../../jhnii3.html">Kafka入门与实践
</a>
    </h1>
    
    
  
  </div>
  <div class="calibreMetaAuthor">
    牟大恩

  </div>
</div>

<div class="calibreMain">

  <div class="calibreEbookContent">
    
      <div class="calibreEbNavTop">
        
          <a href="part0009_split_001.html" class="calibreAPrev">previous page</a>
        

        
          <a href="part0009_split_003.html" class="calibreANext"> next page</a>
        
      </div>
    

    
<h2 id="nav_point_146" class="sigil_not_in_toc">6.2　生产者API应用</h2>

  <p class="zw">本节将通过具体实例来介绍如何通过Producer API开发生产者程序。</p>

  <h3 id="nav_point_147" class="calibre9">6.2.1　单线程生产者</h3>

  <p class="zw">实现一个简单的Kafka生产者一般步骤如下。</p>

  <p class="zw">（1）创建Properties对象，设置生产者级别配置。以下3个配置是必须指定的。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao">bootstrap.servers：配置连接Kafka代理列表，不必包含Kafka集群所有的代理地址，当连接上一个代理后，会从集群元数据信息中获取其他存活的代理信息。但为了保证能够成功连上Kafka集群，在多代理集群的情况下建议至少配置两个代理。</li>

    <li class="di_1ji_wu_xu_lie_biao">key.serializer：配置用于序列化消息Key的类。</li>

    <li class="di_1ji_wu_xu_lie_biao">value.serializer：配置用于序列化消息实际数据的类。</li>
  </ul>

  <p class="zw">（2）根据Properties对象实例化一个KafkaProducer对象。</p>

  <p class="zw">（3）实例化ProducerRecord对象，每条消息对应一个ProducerRecord对象。</p>

  <p class="zw">（4）调用KafkaProducer发送消息的方法将ProducerRecord发送到Kafka相应节点。Kafka提供了两个发送消息的方法，即send(ProducerRecord&lt;String,String&gt;record)方法和send(ProducerRecord &lt;String,String&gt; record,Callback callback)方法，带有回调函数的send()方法要实现org.apache. kafka.clients.producer.Callback接口。如果消息发送发生异常，Callback接口的onCompletion会捕获到相应异常。KafkaProducer默认是异步发送消息，会将消息缓存到消息缓冲区中，当消息在消息缓冲区中累计到一定数量后作为一个RecordBatch再发送。生产者发送消息实质分两个阶段：第一阶段是将消息发送到消息缓冲区；第二阶段是一个Sender线程负责将缓冲区的消息发送到代理，执行真正的I/O操作，而在第一阶段执行完后就返回一个Future对象，根据对Future对象处理方式的不同，KafkaProducer支持两种发送消息方式。</p>

  <ul class="calibre4">
    <li class="di_1ji_wu_xu_lie_biao"><strong class="calibre1">异步方式</strong>：两个send方法都返回一个Future&lt;RecordMetadata&gt;对象，即只负责将消息发送到消息缓冲区，并不等待Sender线程处理结果，若希望了解异步方式消息发送成功与否，可以在回调函数中进行相应处理，当消息被Sender线程处理后会回调Callback。</li>

    <li class="di_1ji_wu_xu_lie_biao"><strong class="calibre1">同步方式</strong>：通过调用send方法返回的Future对象的get()方法以阻塞式获取执行结果，即等待Sender线程处理的最终结果。</li>
  </ul>

  <p class="zw">（5）关闭KafkaProducer，释放连接的资源。</p>

  <p class="zw">介绍完实现一个KafkaProducer的基本步骤之后，现在用Java语言来实现一个KafkaProducer，通过该生产者将模拟股票行情信息发送到Kafka集群中。</p>

  <p class="zw">为了简化程序，我们并没有对接股票真实行情信息，而是通过一组随机数模拟股票行情信息，将股票信息封装为一个JavaBean，该JavaBean对象类名为StockQuotationInfo.Java，同时覆盖其toString()方法，这样便于调用该对象的toString()方法得到的字符串作为消息内容，鉴于篇幅考虑省略了相应字段的get和set方法，该类具体内容见代码清单6-5所示。</p>

  <p class="zw"><strong class="calibre1">代码清单6-5　StockQuotationInfo.Java股票行情信息封装类</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">package com.kafka.action.chapter6.dto;
import Java.io.Serializable;
public class StockQuotationInfo implements Serializable{
    private static final long serialVersionUID = 1L;
    /** 股票代码 */
    private String stockCode;
    /** 股票名称 */
    private String stockName;
    /** 交易时间 */
    private long tradeTime;
    /** 昨日收盘价 */
    private float preClosePrice;
    /** 开盘价 */
    private float openPrice;
    /** 当前价,收盘时即为当日收盘价 */
    private float currentPrice;
    /** 今日最高价 */
    private float highPrice;
    /** 今日最低价 */
    private float lowPrice;
    ……省略了各属性的get和set方法……
    @Override
    public String toString() {
        return this.stockCode + "|" + stockName + "|" + tradeTime + "|" + preClosePrice 
        + "|" + openPrice + "|" + currentPrice + "|" + highPrice + "|" + lowPrice;
    }
}</code></pre>

  <p class="zw">编写一个行情推送的生产者类QuotationProducer.Java，在一个静态代码块中创建一个KafkaProducer，同时定义一个构造Properties对象的initConfig()方法和一个产生股票行情信息的createQuotationInfo()方法，然后在main()方法中调用KafkaProducer对象发送消息，每推送10条股票行情信息让线程休眠2s，该类具体实现如代码清单6-6所示。</p>

  <p class="zw"><strong class="calibre1">代码清单6-6　QuotationProducer.Java股票行情生产者实现类</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">package com.kafka.action.chapter6.producer;

import Java.text.DecimalFormat;
import Java.util.Properties;
import Java.util.Random;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.log4j.Logger;
public class QuotationProducer {
    private static final Logger LOG = Logger.getLogger(QuotationProducer.class);
    /** 设置实例生产消息的总数 */
    private static final int MSG_SIZE = 100;
    /** 主题名称 */
    private static final String TOPIC = "stock-quotation";
    /** Kafka集群 */
    private static final String BROKER_LIST = 
    " server-1:9092,server-2:9092,server-3:9092 ";
    private static KafkaProducer&lt;String, String&gt; producer = null;
    static {
        // 1.构造用于实例化KafkaProducer的Properties信息
        Properties configs = initConfig();
        // 2.初始化一个KafkaProducer
        producer = new KafkaProducer&lt;String, String&gt;(configs);
    }

    /**
     * 初始化Kafka配置
     * @return
     */
    private static Properties initConfig() {
        Properties properties = new Properties();
        // Kafka broker列表
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        // 设置序列化类
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
                       StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
                       StringSerializer.class.getName());
        return properties;
    }

    /**
     * 生产股票行情信息
     * @return
     */
    private static StockQuotationInfo createQuotationInfo() {
        StockQuotationInfo quotationInfo = new StockQuotationInfo();
        // 随机产生1到10之间的整数，然后与600100相加组成股票代码
        Random r = new Random();
        Integer stockCode = 600100 + r.nextInt(10);
        // 随机产生一个0到1之间的浮点数
        float random = (float) Math.random();
        // 设置涨跌规则
        if (random / 2 &lt; 0.5) {
            random = -random;
        }
        DecimalFormat decimalFormat = new DecimalFormat(".00");// 设置保存两位有效数字
        quotationInfo.setCurrentPrice(Float.valueOf(decimalFormat.format(11 + 
        random)));// 设置最新价在11元浮动
        quotationInfo.setPreClosePrice(11.80f);// 设置昨日收盘价为固定值
        quotationInfo.setOpenPrice(11.5f);// 设置开盘价
        quotationInfo.setLowPrice(10.5f);// 设置最低价，并不考虑10%限制，
                                         //以及当前价是否已是最低价
        quotationInfo.setHighPrice(12.5f);// 设置最高价，并不考虑10%限制，
                                          //以及当前价是否已是最高价    
        quotationInfo.setStockCode(stockCode.toString());
        quotationInfo.setTradeTime(System.currentTimeMillis());
        quotationInfo.setStockName("股票-" + stockCode);
        return quotationInfo;
    }

    public static void main(String[] args) {
        ProducerRecord&lt;String, String&gt; record = null;
        StockQuotationInfo quotationInfo = null;
        try {
            int num = 0;
            for (int i = 0; i &lt; MSG_SIZE; i++) {
                quotationInfo = createQuotationInfo();
                record = new ProducerRecord&lt;String, String&gt;(TOPIC, null, 
                quotationInfo.getTradeTime(),quotationInfo.getStockCode(),
                quotationInfo.toString());
                producer.send(record);// 异步发送消息
                if (num++ % 10 == 0) {
                    Thread.sleep(2000L);// 休眠2s
                }
            }
        } catch (InterruptedException e) {
            LOG.error("Send message occurs exception", e);
        } finally {
            producer.close();
        }
    }
}</code></pre>

  <p class="zw">在运行股票行情生产者之前，我们先在Kafka集群中创建一个名为“stock-quotation”的主题，该主题有1个副本、6个分区。进入$KAFKA_HOME/bin目录下，执行以下创建主题命令：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">./kafka-topics.sh --create --zookeeper server-1:2181,server-2:2181,server-3:2181 --replication-factor 1 --partitions 6 --topic stock-quotation</code></pre>

  <p class="zw">最后，运行QuotationProducer.Java类，这里直接在Eclipse中运行该类。该类执行后，进入$KAFKA_HOME/bin目录下，执行以下命令查看某个分区的日志文件信息：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">kafka-run-class.sh kafka.tools.DumpLogSegments --files /opt/data/kafka-logs/stock-quotation-0/00000000000000000000.log --print-data-log</code></pre>

  <p class="zw">在终端部分输出信息片段如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">offset: 19 position: 1615 CreateTime: 1488371576746 isvalid: true payloadsize: 45 magic: 1 compresscodec: NoCompressionCodec crc: 325016124 keysize: 6 key: 600107 payload: 600107|股票-600107|1488371576746|11.8|10.73
offset: 20 position: 1700 CreateTime: 1488371598758 isvalid: true payloadsize: 45 magic: 1 compresscodec: NoCompressionCodec crc: 2038453447 keysize: 6 key: 600107 payload: 600107|股票-600107|1488371598758|11.8|10.14</code></pre>

  <p class="zw">由于我们以股票代码作为消息的Key，因此在默认分区分配策略下，同一支股票的行情信息会发送到同一个分区下，这样也便于我们后期对消息进行处理。</p>

  <p class="zw">如果我们希望在消息发送完成后获取消息的一些信息，例如获取消息偏移量及消息被发送到哪个分区，那么我们可以在发送消息时，指定回调CallBack，只需对QuotationProducer.Java类中发送消息这块代码稍微进行修改，如代码清单6-7所示。</p>

  <p class="zw"><strong class="calibre1">代码清单6-7　股票行情生产者发送消息时指定回调的实现逻辑</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">    public static void main(String[] args) {
        ProducerRecord&lt;String, String&gt; record = null;
        StockQuotationInfo quotationInfo = null;
        try {
            int num = 0;
            for (int i = 0; i &lt; MSG_SIZE; i++) {
                quotationInfo = createQuotationInfo();
                record = new ProducerRecord&lt;String, String&gt;(TOPIC, null, 
                quotationInfo.getTradeTime(),quotationInfo.getStockCode(),
                quotationInfo.toString());
                // 发送消息时指定一个Callback，实现onCompletion()方法，
                // 在成功发送后获取消息的偏移量及分区
                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metaData, Exception 
                    exception) {
                        if(null!=exception){// 发送异常记录异常信息
                            LOG.error("Send message occurs exception.",exception);
                        }
                        if(null!=metaData){
                            LOG.info(String.format("offset:%s,partition:%s",
                            metaData.offset(),metaData.partition()));
                       }    
                    }
                });
                if (num++ % 10 == 0) {
                    Thread.sleep(2000L);// 休眠2秒
                }
            }
        } catch (InterruptedException e) {
            LOG.error("Send message occurs exception", e);
        } finally {
            producer.close();
        }
    }</code></pre>

  <p class="zw">再次运行该生产者，在控制台会打印每条消息的偏移量及分区信息。控制台打印的部分日志信息如下：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">2017-03-01 20:54:40 [INFO]-[com.kafka.action.chapter6.producer.QuotationProducer] offset:183,partition:4
2017-03-01 20:54:42 [INFO]-[com.kafka.action.chapter6.producer.QuotationProducer] offset:109,partition:1
2017-03-01 20:54:42 [INFO]-[com.kafka.action.chapter6.producer.QuotationProducer] offset:110,partition:1
2017-03-01 20:54:42 [INFO]-[com.kafka.action.chapter6.producer.QuotationProducer] offset:184,partition:4</code></pre>

  <h3 id="nav_point_148" class="calibre9">6.2.2　多线程生产者</h3>

  <p class="zw">为了提升Kafka发送消息的吞吐量，在数据量比较大同时对消息顺序也没有严格要求的情况下，可以采用多线程的方式。实现多线程生产者一般有两种方式：只实例化一个KafkaProducer对象运行多个线程共享该生产者发送消息；实例化多个KafkaProducer对象。由于KafkaProducer是线程安全，经验证多个线程共享一个实例比每个线程各自实例化一个KafkaProducer对象在性能上要好很多。</p>

  <p class="zw">本小节基于上一节单线程生产者实现方式进行修改，采用实例化一个KafkaProducer对象，然后启动多个线程共享该KafkaProducer实例的方式来介绍Kafka生产者多线程的实现方式。首先定义一个线程类KafkaProducerThread，该线程类持有一个KafkaProducer的引用，在线程内部调用外部传入的KafkaProducer对象发送消息。该线程类的具体实现如代码清单6-8所示。</p>

  <p class="zw"><strong class="calibre1">代码清单6-8　线程类KafkaProducerThread的具体实现</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">package com.kafka.action.chapter6.producer;
import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.log4j.Logger;

public class KafkaProducerThread implements Runnable{

    private static final Logger LOG = Logger.getLogger(KafkaProducerThread.class);

    private  KafkaProducer&lt;String, String&gt; producer = null;

    private  ProducerRecord&lt;String, String&gt; record = null;

    public KafkaProducerThread(KafkaProducer&lt;String, String&gt; producer, 
    ProducerRecord&lt;String, String&gt; record) {
        this.producer = producer;
        this.record = record;
    }

    @Override
    public void run() {
        producer.send(record,new Callback() {

            @Override
            public void onCompletion(RecordMetadata metaData, Exception
            exception) {
                if (null != exception) {// 发送异常记录异常信息
                    LOG.error("Send message occurs exception.", exception);
                }
                if (null != metaData) {
                    LOG.info(String.format("offset:%s,partition:%s",
                    metaData.offset(), metaData.partition()));
                }
            }
        });
    }
}</code></pre>

  <p class="zw">然后创建一个固定线程数量的线程池，这些线程共享同一个KafkaProducer实例：</p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">ExecutorService executor = Executors.newFixedThreadPool(THREADS_NUMS);
executor.submit(new KafkaProducerThread(producer, record));</code></pre>

  <p class="zw">修改main方法发送消息的逻辑如代码清单6-9所示。</p>

  <p class="zw"><strong class="calibre1">代码清单6-9　多线程发送消息的具体实现</strong></p>
  <pre class="dai_ma_wu_xing_hao"><code class="calibre10">public static void main(String[] args) {
    ProducerRecord&lt;String, String&gt; record = null;
    StockQuotationInfo quotationInfo = null;
    ExecutorService executor = Executors.newFixedThreadPool(THREADS_NUMS);
    long current = System.currentTimeMillis();
    try {
        for (int i = 0; i &lt; MSG_SIZE; i++) {
            quotationInfo = createQuotationInfo();
            record = new ProducerRecord&lt;String, String&gt;(TOPIC, null,
                     quotationInfo.getTradeTime(),
                     quotationInfo.getStockCode(), quotationInfo.toString());
            executor.submit(new KafkaProducerThread(producer, record));
        }
    } catch (Exception e) {
        LOG.error("Send message occurs exception", e);
    } finally {
        producer.close();
        executor.shutdown();
    }
}</code></pre>

  

  </div>

  
  <div class="calibreToc">
    <h2><a href="../../jhnii3.html"> Table of contents</a></h2>
     <div>
  <ul>
    <li>
      <a href="part0001.html#UGI0-b6aea6b975744e46b4d1346849966264">版权信息</a>
    </li>
    <li>
      <a href="part0002.html#1T140-b6aea6b975744e46b4d1346849966264">内容提要</a>
    </li>
    <li>
      <a href="part0003_split_000.html#2RHM0-b6aea6b975744e46b4d1346849966264">前言</a>
    </li>
    <li>
      <a href="part0004_split_000.html#3Q280-b6aea6b975744e46b4d1346849966264">第1章 Kafka简介</a>
      <ul>
        <li>
          <a href="part0004_split_001.html">1.1 Kafka背景</a>
        </li>
        <li>
          <a href="part0004_split_002.html">1.2 Kafka基本结构</a>
        </li>
        <li>
          <a href="part0004_split_003.html">1.3 Kafka基本概念</a>
        </li>
        <li>
          <a href="part0004_split_004.html">1.4 Kafka设计概述</a>
          <ul>
            <li>
              <a href="part0004_split_004.html#nav_point_13">1.4.1 Kafka设计动机</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_14">1.4.2 Kafka特性</a>
            </li>
            <li>
              <a href="part0004_split_004.html#nav_point_15">1.4.3 Kafka应用场景</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0004_split_005.html">1.5 本书导读</a>
        </li>
        <li>
          <a href="part0004_split_006.html">1.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0005_split_000.html#4OIQ0-b6aea6b975744e46b4d1346849966264">第2章 Kafka安装配置</a>
      <ul>
        <li>
          <a href="part0005_split_001.html">2.1 基础环境配置</a>
          <ul>
            <li>
              <a href="part0005_split_001.html#nav_point_20">2.1.1 JDK安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_21">2.1.2 SSH安装配置</a>
            </li>
            <li>
              <a href="part0005_split_001.html#nav_point_22">2.1.3 ZooKeeper环境</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_002.html">2.2 Kafka单机环境部署</a>
          <ul>
            <li>
              <a href="part0005_split_002.html#nav_point_24">2.2.1 Windows环境安装Kafka</a>
            </li>
            <li>
              <a href="part0005_split_002.html#nav_point_25">2.2.2 Linux环境安装Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_003.html">2.3 Kafka伪分布式环境部署</a>
        </li>
        <li>
          <a href="part0005_split_004.html">2.4 Kafka集群环境部署</a>
        </li>
        <li>
          <a href="part0005_split_005.html">2.5 Kafka Manager安装</a>
        </li>
        <li>
          <a href="part0005_split_006.html">2.6 Kafka源码编译</a>
          <ul>
            <li>
              <a href="part0005_split_006.html#nav_point_30">2.6.1 Scala安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_31">2.6.2 Gradle安装配置</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_32">2.6.3 Kafka源码编译</a>
            </li>
            <li>
              <a href="part0005_split_006.html#nav_point_33">2.6.4 Kafka导入Eclipse</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0005_split_007.html">2.7 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0006_split_000.html#5N3C0-b6aea6b975744e46b4d1346849966264">第3章 Kafka核心组件</a>
      <ul>
        <li>
          <a href="part0006_split_001.html">3.1 延迟操作组件</a>
          <ul>
            <li>
              <a href="part0006_split_001.html#nav_point_37">3.1.1 DelayedOperation</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_38">3.1.2 DelayedOperationPurgatory</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_39">3.1.3 DelayedProduce</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_40">3.1.4 DelayedFetch</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_41">3.1.5 DelayedJoin</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_42">3.1.6 DelayedHeartbeat</a>
            </li>
            <li>
              <a href="part0006_split_001.html#nav_point_43">3.1.7 DelayedCreateTopics</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_002.html">3.2 控制器</a>
          <ul>
            <li>
              <a href="part0006_split_002.html#nav_point_45">3.2.1 控制器初始化</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_46">3.2.2 控制器选举过程</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_47">3.2.3 故障转移</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_48">3.2.4 代理上线与下线</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_49">3.2.5 主题管理</a>
            </li>
            <li>
              <a href="part0006_split_002.html#nav_point_50">3.2.6 分区管理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_003.html">3.3 协调器</a>
          <ul>
            <li>
              <a href="part0006_split_003.html#nav_point_52">3.3.1 消费者协调器</a>
            </li>
            <li>
              <a href="part0006_split_003.html#nav_point_53">3.3.2 组协调器</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_004.html">3.4 网络通信服务</a>
          <ul>
            <li>
              <a href="part0006_split_004.html#nav_point_55">3.4.1 Acceptor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_56">3.4.2 Processor</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_57">3.4.3 RequestChannel</a>
            </li>
            <li>
              <a href="part0006_split_004.html#nav_point_58">3.4.4 SocketServer启动过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_005.html">3.5 日志管理器</a>
          <ul>
            <li>
              <a href="part0006_split_005.html#nav_point_60">3.5.1 Kafka日志结构</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_61">3.5.2 日志管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_62">3.5.3 日志加载及恢复</a>
            </li>
            <li>
              <a href="part0006_split_005.html#nav_point_63">3.5.4 日志清理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_006.html">3.6 副本管理器</a>
          <ul>
            <li>
              <a href="part0006_split_006.html#nav_point_65">3.6.1 分区</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_66">3.6.2 副本</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_67">3.6.3 副本管理器启动过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_68">3.6.4 副本过期检查</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_69">3.6.5 追加消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_70">3.6.6 拉取消息</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_71">3.6.7 副本同步过程</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_72">3.6.8 副本角色转换</a>
            </li>
            <li>
              <a href="part0006_split_006.html#nav_point_73">3.6.9 关闭副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0006_split_007.html">3.7 Handler</a>
        </li>
        <li>
          <a href="part0006_split_008.html">3.8 动态配置管理器</a>
        </li>
        <li>
          <a href="part0006_split_009.html">3.9 代理健康检测</a>
        </li>
        <li>
          <a href="part0006_split_010.html">3.10 Kafka内部监控</a>
        </li>
        <li>
          <a href="part0006_split_011.html">3.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0007_split_000.html#6LJU0-b6aea6b975744e46b4d1346849966264">第4章 Kafka核心流程分析</a>
      <ul>
        <li>
          <a href="part0007_split_001.html">4.1 KafkaServer启动流程分析</a>
        </li>
        <li>
          <a href="part0007_split_002.html">4.2 创建主题流程分析</a>
          <ul>
            <li>
              <a href="part0007_split_002.html#nav_point_82">4.2.1 客户端创建主题</a>
            </li>
            <li>
              <a href="part0007_split_002.html#nav_point_83">4.2.2 分区副本分配</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_003.html">4.3 生产者</a>
          <ul>
            <li>
              <a href="part0007_split_003.html#nav_point_85">4.3.1 Eclipse运行生产者源码</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_86">4.3.2 生产者重要配置说明</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_87">4.3.3 OldProducer执行流程</a>
            </li>
            <li>
              <a href="part0007_split_003.html#nav_point_88">4.3.4 KafkaProducer实现原理</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_004.html">4.4 消费者</a>
          <ul>
            <li>
              <a href="part0007_split_004.html#nav_point_90">4.4.1 旧版消费者</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_91">4.4.2 KafkaConsumer初始化</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_92">4.4.3 消费订阅</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_93">4.4.4 消费消息</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_94">4.4.5 消费偏移量提交</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_95">4.4.6 心跳探测</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_96">4.4.7 分区数与消费者线程的关系</a>
            </li>
            <li>
              <a href="part0007_split_004.html#nav_point_97">4.4.8 消费者平衡过程</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0007_split_005.html">4.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0008_split_000.html#7K4G0-b6aea6b975744e46b4d1346849966264">第5章 Kafka基本操作实战</a>
      <ul>
        <li>
          <a href="part0008_split_001.html">5.1 KafkaServer管理</a>
          <ul>
            <li>
              <a href="part0008_split_001.html#nav_point_101">5.1.1 启动Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_102">5.1.2 启动Kafka集群</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_103">5.1.3 关闭Kafka单个节点</a>
            </li>
            <li>
              <a href="part0008_split_001.html#nav_point_104">5.1.4 关闭Kafka集群</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_002.html">5.2 主题管理</a>
          <ul>
            <li>
              <a href="part0008_split_002.html#nav_point_106">5.2.1 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_107">5.2.2 删除主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_108">5.2.3 查看主题</a>
            </li>
            <li>
              <a href="part0008_split_002.html#nav_point_109">5.2.4 修改主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_003.html">5.3 生产者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_003.html#nav_point_111">5.3.1 启动生产者</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_112">5.3.2 创建主题</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_113">5.3.3 查看消息</a>
            </li>
            <li>
              <a href="part0008_split_003.html#nav_point_114">5.3.4 生产者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_004.html">5.4 消费者基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_004.html#nav_point_116">5.4.1 消费消息</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_117">5.4.2 单播与多播</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_118">5.4.3 查看消费偏移量</a>
            </li>
            <li>
              <a href="part0008_split_004.html#nav_point_119">5.4.4 消费者性能测试工具</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_005.html">5.5 配置管理</a>
          <ul>
            <li>
              <a href="part0008_split_005.html#nav_point_121">5.5.1 主题级别配置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_122">5.5.2 代理级别设置</a>
            </li>
            <li>
              <a href="part0008_split_005.html#nav_point_123">5.5.3 客户端/用户级别配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_006.html">5.6 分区操作</a>
          <ul>
            <li>
              <a href="part0008_split_006.html#nav_point_125">5.6.1 分区Leader平衡</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_126">5.6.2 分区迁移</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_127">5.6.3 增加分区</a>
            </li>
            <li>
              <a href="part0008_split_006.html#nav_point_128">5.6.4 增加副本</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_007.html">5.7 连接器基本操作</a>
          <ul>
            <li>
              <a href="part0008_split_007.html#nav_point_130">5.7.1 独立模式</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_131">5.7.2 REST风格API应用</a>
            </li>
            <li>
              <a href="part0008_split_007.html#nav_point_132">5.7.3 分布式模式</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_008.html">5.8 Kafka Manager应用</a>
        </li>
        <li>
          <a href="part0008_split_009.html">5.9 Kafka安全机制</a>
          <ul>
            <li>
              <a href="part0008_split_009.html#nav_point_135">5.9.1 利用SASL/PLAIN进行身份认证</a>
            </li>
            <li>
              <a href="part0008_split_009.html#nav_point_136">5.9.2 权限控制</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0008_split_010.html">5.10 镜像操作</a>
        </li>
        <li>
          <a href="part0008_split_011.html">5.11 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0009_split_000.html#8IL20-b6aea6b975744e46b4d1346849966264">第6章 Kafka API编程实战</a>
      <ul>
        <li>
          <a href="part0009_split_001.html">6.1 主题管理</a>
          <ul>
            <li>
              <a href="part0009_split_001.html#nav_point_141">6.1.1 创建主题</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_142">6.1.2 修改主题级别配置</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_143">6.1.3 增加分区</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_144">6.1.4 分区副本重分配</a>
            </li>
            <li>
              <a href="part0009_split_001.html#nav_point_145">6.1.5 删除主题</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_002.html">6.2 生产者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_002.html#nav_point_147">6.2.1 单线程生产者</a>
            </li>
            <li>
              <a href="part0009_split_002.html#nav_point_148">6.2.2 多线程生产者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_003.html">6.3 消费者API应用</a>
          <ul>
            <li>
              <a href="part0009_split_003.html#nav_point_150">6.3.1 旧版消费者API应用</a>
            </li>
            <li>
              <a href="part0009_split_003.html#nav_point_151">6.3.2 新版消费者API应用</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_004.html">6.4 自定义组件实现</a>
          <ul>
            <li>
              <a href="part0009_split_004.html#nav_point_153">6.4.1 分区器</a>
            </li>
            <li>
              <a href="part0009_split_004.html#nav_point_154">6.4.2 序列化与反序列化</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_005.html">6.5 Spring与Kafka整合应用</a>
          <ul>
            <li>
              <a href="part0009_split_005.html#nav_point_156">6.5.1 生产者</a>
            </li>
            <li>
              <a href="part0009_split_005.html#nav_point_157">6.5.2 消费者</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0009_split_006.html">6.6 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0010_split_000.html#9H5K0-b6aea6b975744e46b4d1346849966264">第7章 Kafka Streams</a>
      <ul>
        <li>
          <a href="part0010_split_001.html">7.1 Kafka Streams简介</a>
        </li>
        <li>
          <a href="part0010_split_002.html">7.2 Kafka Streams基本概念</a>
          <ul>
            <li>
              <a href="part0010_split_002.html#nav_point_162">7.2.1 流</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_163">7.2.2 流处理器</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_164">7.2.3 处理器拓扑</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_165">7.2.4 时间</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_166">7.2.5 状态</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_167">7.2.6 KStream和KTable</a>
            </li>
            <li>
              <a href="part0010_split_002.html#nav_point_168">7.2.7 窗口</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_003.html">7.3 Kafka Streams API介绍</a>
          <ul>
            <li>
              <a href="part0010_split_003.html#nav_point_170">7.3.1 KStream与KTable</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_171">7.3.2 窗口操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_172">7.3.3 连接操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_173">7.3.4 变换操作</a>
            </li>
            <li>
              <a href="part0010_split_003.html#nav_point_174">7.3.5 聚合操作</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_004.html">7.4 接口恶意访问自动检测</a>
          <ul>
            <li>
              <a href="part0010_split_004.html#nav_point_176">7.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0010_split_004.html#nav_point_177">7.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0010_split_005.html">7.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0011_split_000.html#AFM60-b6aea6b975744e46b4d1346849966264">第8章 Kafka数据采集应用</a>
      <ul>
        <li>
          <a href="part0011_split_001.html">8.1 Log4j集成Kafka应用</a>
          <ul>
            <li>
              <a href="part0011_split_001.html#nav_point_181">8.1.1 应用描述</a>
            </li>
            <li>
              <a href="part0011_split_001.html#nav_point_182">8.1.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_002.html">8.2 Kafka与Flume整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_002.html#nav_point_184">8.2.1 Flume简介</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_185">8.2.2 Flume与Kafka比较</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_186">8.2.3 Flume的安装配置</a>
            </li>
            <li>
              <a href="part0011_split_002.html#nav_point_187">8.2.4 Flume采集日志写入Kafka</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_003.html">8.3 Kafka与Flume和HDFS整合应用</a>
          <ul>
            <li>
              <a href="part0011_split_003.html#nav_point_189">8.3.1 Hadoop安装配置</a>
            </li>
            <li>
              <a href="part0011_split_003.html#nav_point_190">8.3.2 Flume采集Kafka消息写入HDFS</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0011_split_004.html">8.4 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0012_split_000.html#BE6O0-b6aea6b975744e46b4d1346849966264">第9章 Kafka与ELK整合应用</a>
      <ul>
        <li>
          <a href="part0012_split_001.html">9.1 ELK环境搭建</a>
          <ul>
            <li>
              <a href="part0012_split_001.html#nav_point_194">9.1.1 Elasticsearch安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_195">9.1.2 Logstash安装配置</a>
            </li>
            <li>
              <a href="part0012_split_001.html#nav_point_196">9.1.3 Kibana安装配置</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_002.html">9.2 Kafka与Logstash整合</a>
          <ul>
            <li>
              <a href="part0012_split_002.html#nav_point_198">9.2.1 Logstash收集日志到Kafka</a>
            </li>
            <li>
              <a href="part0012_split_002.html#nav_point_199">9.2.2 Logstash从Kafka消费日志</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_003.html">9.3 日志采集分析系统</a>
          <ul>
            <li>
              <a href="part0012_split_003.html#nav_point_201">9.3.1 Flume采集日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_202">9.3.2 Logstash拉取日志配置</a>
            </li>
            <li>
              <a href="part0012_split_003.html#nav_point_203">9.3.3 Kibana日志展示</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_004.html">9.4 服务器性能监控系统</a>
          <ul>
            <li>
              <a href="part0012_split_004.html#nav_point_205">9.4.1 Metricbeat安装</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_206">9.4.2 采集信息存储到Elasticsearch</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_207">9.4.3 加载beats-dashboards</a>
            </li>
            <li>
              <a href="part0012_split_004.html#nav_point_208">9.4.4 服务器性能监控系统具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0012_split_005.html">9.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0013_split_000.html#CCNA0-b6aea6b975744e46b4d1346849966264">第10章 Kafka与Spark整合应用</a>
      <ul>
        <li>
          <a href="part0013_split_001.html">10.1 Spark简介</a>
        </li>
        <li>
          <a href="part0013_split_002.html">10.2 Spark基本操作</a>
          <ul>
            <li>
              <a href="part0013_split_002.html#nav_point_213">10.2.1 Spark安装</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_214">10.2.2 Spark shell应用</a>
            </li>
            <li>
              <a href="part0013_split_002.html#nav_point_215">10.2.3 spark-submit提交作业</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_003.html">10.3 Spark在智能投顾领域应用</a>
          <ul>
            <li>
              <a href="part0013_split_003.html#nav_point_217">10.3.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_003.html#nav_point_218">10.3.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_004.html">10.4 热搜词统计</a>
          <ul>
            <li>
              <a href="part0013_split_004.html#nav_point_220">10.4.1 应用描述</a>
            </li>
            <li>
              <a href="part0013_split_004.html#nav_point_221">10.4.2 具体实现</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="part0013_split_005.html">10.5 小结</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="part0014_split_000.html#DB7S0-b6aea6b975744e46b4d1346849966264">欢迎来到异步社区！</a>
    </li>
  </ul>
</div>


  </div>
  

  <div class="calibreEbNav">
    
      <a href="part0009_split_001.html" class="calibreAPrev">previous page</a>
    

    <a href="../../jhnii3.html" class="calibreAHome"> start</a>

    
      <a href="part0009_split_003.html" class="calibreANext"> next page</a>
    
  </div>

</div>

</body>
</html>
